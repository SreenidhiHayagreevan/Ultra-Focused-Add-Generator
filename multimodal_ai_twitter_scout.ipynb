{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86WbyFj1YXyT"
      },
      "source": [
        "# ğŸ§  Multimodal AI Model Scout â€” Twitter Top 5 (Last 7 Days)\n",
        "**Narrow focus:** Recent multimodal model releases/benchmarks on par with Claude Sonnet or GPT-4o/5-class models  \n",
        "**Geos:** San Francisco Â· Chicago Â· New York  \n",
        "**Platforms:** Twitter (Yutori v2) + Tavily fallback  \n",
        "**Output:** Top 5 highest-engagement tweets + top Tavily content ranked by viral score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qije82jqYXyV"
      },
      "source": [
        "# â”€â”€ Install â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "!pip install tavily-python requests -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpQnzr-TYXyW",
        "outputId": "635beb3a-48ab-409f-d1d2-e9069c7ca83e"
      },
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# MULTIMODAL AI TWITTER SCOUT\n",
        "# Finds top viral tweets + social content about new multimodal models\n",
        "# that benchmark at Claude Sonnet / GPT-4o / GPT-5.2 level\n",
        "# Geo-anchored: SF Â· Chicago Â· NYC tech communities\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "import os, json, time, re\n",
        "from getpass import getpass\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from typing import List, Optional\n",
        "from datetime import datetime, timezone\n",
        "from collections import Counter\n",
        "\n",
        "import requests\n",
        "from tavily import TavilyClient\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# â˜… CONFIG â€” Tune these to shift focus\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "# Narrow topics: new multimodal models competing with Claude Sonnet / GPT-4o class\n",
        "TOPICS = [\n",
        "    \"multimodal model benchmark Claude Sonnet GPT-4o\",\n",
        "    \"new vision language model release 2025 2026\",\n",
        "    \"Gemini Grok Llama multimodal release benchmark\",\n",
        "    \"open source multimodal model GPT-5 Claude level\",\n",
        "    \"multimodal AI demo event SF Chicago NYC\",\n",
        "]\n",
        "\n",
        "# Geography anchors injected into Twitter queries\n",
        "GEO_TERMS = [\"San Francisco\", \"Chicago\", \"New York\"]\n",
        "\n",
        "# Recency window\n",
        "RECENCY = \"week\"   # \"day\" | \"week\" | \"month\"\n",
        "\n",
        "# How many Tavily results per query\n",
        "MAX_RESULTS = 5\n",
        "\n",
        "# Twitter: pull this many candidates per query, return top N\n",
        "TWITTER_PULL = 50\n",
        "TOP_N_TWEETS = 5    # â† final top tweets shown\n",
        "\n",
        "# Tavily platforms to search\n",
        "PLATFORMS = {\n",
        "    \"twitter\":  True,\n",
        "    \"youtube\":  True,   # demo/event videos\n",
        "    \"reddit\":   True,\n",
        "    \"linkedin\": False,\n",
        "    \"blogs\":    False,\n",
        "}\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# QUERY TEMPLATES â€” geo-injected for local tech community signal\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "# Tavily query templates\n",
        "QUERY_TEMPLATES = {\n",
        "    \"twitter\": [\n",
        "        \"{topic} site:twitter.com OR site:x.com viral 2025 2026\",\n",
        "        \"{topic} site:x.com release demo benchmark thread\",\n",
        "    ],\n",
        "    \"youtube\": [\n",
        "        \"{topic} site:youtube.com demo release 2025 2026\",\n",
        "        \"{topic} youtube multimodal benchmark review\",\n",
        "    ],\n",
        "    \"reddit\": [\n",
        "        \"{topic} site:reddit.com r/MachineLearning OR r/LocalLLaMA OR r/artificial 2026\",\n",
        "        \"{topic} reddit multimodal release hot 2025 2026\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Twitter v2 queries â€” narrow + geo-anchored\n",
        "TWITTER_V2_QUERIES = [\n",
        "    # Core multimodal release signal\n",
        "    '(multimodal model OR vision language model) (release OR launch OR benchmark) (\"Claude Sonnet\" OR \"GPT-4o\" OR \"GPT-5\") -is:retweet lang:en',\n",
        "    # Tech event / demo in target cities\n",
        "    '(multimodal AI OR vision model) (\"San Francisco\" OR \"Chicago\" OR \"New York\") (demo OR event OR keynote) -is:retweet lang:en',\n",
        "    # Benchmark comparisons going viral\n",
        "    '(new model OR multimodal) (\"on par with\" OR \"beats\" OR \"matches\" OR \"rivals\") (Claude OR GPT OR Sonnet) -is:retweet lang:en',\n",
        "    # Open-source releases that got traction\n",
        "    '(open source multimodal OR open-source VLM) (release OR launch OR \"just dropped\") 2025 OR 2026 -is:retweet lang:en',\n",
        "    # Viral demo videos of multimodal models\n",
        "    '(multimodal model) (\"went viral\" OR viral OR \"blew up\") (video OR demo OR thread) -is:retweet lang:en',\n",
        "]\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# VIRAL SIGNALS\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "VIRAL_SIGNAL_WORDS = [\n",
        "    \"went viral\", \"blew up\", \"breaking\", \"just released\", \"just dropped\",\n",
        "    \"just announced\", \"everyone is talking\", \"thread\", \"repost\",\n",
        "    \"comments\", \"likes\", \"views\", \"demo\", \"benchmark\", \"beats\",\n",
        "    \"on par with\", \"rivals\", \"open source\", \"leaked\", \"exclusive\",\n",
        "    \"multimodal\", \"vision\", \"release\", \"first look\",\n",
        "]\n",
        "\n",
        "def detect_viral_signals(text):\n",
        "    t = text.lower()\n",
        "    return [s for s in VIRAL_SIGNAL_WORDS if s.lower() in t]\n",
        "\n",
        "def detect_platform(url, fallback):\n",
        "    u = url.lower()\n",
        "    if \"twitter.com\" in u or \"x.com\" in u: return \"twitter\"\n",
        "    if \"youtube.com\" in u or \"youtu.be\" in u: return \"youtube\"\n",
        "    if \"reddit.com\" in u: return \"reddit\"\n",
        "    if \"linkedin.com\" in u: return \"linkedin\"\n",
        "    return fallback\n",
        "\n",
        "def detect_content_type(url, title):\n",
        "    u, t = url.lower(), title.lower()\n",
        "    if \"twitter.com\" in u or \"x.com\" in u:\n",
        "        return \"thread\" if \"thread\" in t else \"post\"\n",
        "    if \"youtube.com\" in u or \"youtu.be\" in u: return \"video\"\n",
        "    if \"reddit.com\" in u: return \"thread\"\n",
        "    return \"article\"\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# DATA CLASSES\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "@dataclass\n",
        "class ScoutedPost:\n",
        "    platform:        str\n",
        "    content_type:    str\n",
        "    title:           str\n",
        "    url:             str\n",
        "    snippet:         str\n",
        "    full_content:    str\n",
        "    relevance_score: float\n",
        "    topic:           str\n",
        "    query_used:      str\n",
        "    published_date:  Optional[str]  = None\n",
        "    viral_signals:   List[str]      = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class ScoutOutput:\n",
        "    agent:             str       = \"multimodal_ai_scout\"\n",
        "    timestamp:         str       = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())\n",
        "    topics_scouted:    List[str] = field(default_factory=list)\n",
        "    platforms_scouted: List[str] = field(default_factory=list)\n",
        "    posts:             List[ScoutedPost] = field(default_factory=list)\n",
        "    total_found:       int       = 0\n",
        "    queries_run:       int       = 0\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# TAVILY SCOUT\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "class TavilySocialScout:\n",
        "    def __init__(self, api_key):\n",
        "        self.client = TavilyClient(api_key=api_key)\n",
        "\n",
        "    def _query(self, query, topic, platform, recency, max_results):\n",
        "        days_map = {\"day\": 2, \"week\": 7, \"month\": 30}\n",
        "        try:\n",
        "            resp = self.client.search(\n",
        "                query=query,\n",
        "                search_depth=\"advanced\",\n",
        "                max_results=max_results,\n",
        "                topic=\"news\",\n",
        "                days=days_map.get(recency, 7),\n",
        "                include_answer=False,\n",
        "                include_raw_content=False,\n",
        "            )\n",
        "        except Exception:\n",
        "            try:\n",
        "                resp = self.client.search(\n",
        "                    query=query,\n",
        "                    search_depth=\"advanced\",\n",
        "                    max_results=max_results,\n",
        "                    include_answer=False,\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"      âš ï¸  Failed: {e}\")\n",
        "                return []\n",
        "        posts = []\n",
        "        for r in resp.get(\"results\", []):\n",
        "            url, title, content = r.get(\"url\",\"\"), r.get(\"title\",\"\"), r.get(\"content\",\"\")\n",
        "            posts.append(ScoutedPost(\n",
        "                platform        = detect_platform(url, platform),\n",
        "                content_type    = detect_content_type(url, title),\n",
        "                title           = title,\n",
        "                url             = url,\n",
        "                snippet         = content[:400],\n",
        "                full_content    = content,\n",
        "                relevance_score = round(r.get(\"score\", 0.0), 4),\n",
        "                topic           = topic,\n",
        "                query_used      = query,\n",
        "                published_date  = r.get(\"published_date\"),\n",
        "                viral_signals   = detect_viral_signals(content),\n",
        "            ))\n",
        "        return posts\n",
        "\n",
        "    def run(self, topics, platforms, recency=\"week\", max_results=5):\n",
        "        active = [p for p, on in platforms.items() if on]\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ğŸ“¡ TAVILY MULTIMODAL AI SCOUT\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"   Topics    : {len(topics)} narrow queries\")\n",
        "        print(f\"   Platforms : {active}\")\n",
        "        print(f\"   Recency   : last {recency}\")\n",
        "\n",
        "        output = ScoutOutput(topics_scouted=topics, platforms_scouted=active)\n",
        "        seen, q_count = set(), 0\n",
        "\n",
        "        for topic in topics:\n",
        "            print(f\"\\nğŸ” '{topic[:60]}'\")\n",
        "            for platform, enabled in platforms.items():\n",
        "                if not enabled:\n",
        "                    continue\n",
        "                for tmpl in QUERY_TEMPLATES.get(platform, [])[:2]:\n",
        "                    query = tmpl.replace(\"{topic}\", topic)\n",
        "                    print(f\"   [{platform.upper():10s}] {query[:65]}\")\n",
        "                    posts = self._query(query, topic, platform, recency, max_results)\n",
        "                    q_count += 1\n",
        "                    new = 0\n",
        "                    for p in posts:\n",
        "                        if p.url not in seen:\n",
        "                            seen.add(p.url)\n",
        "                            output.posts.append(p)\n",
        "                            new += 1\n",
        "                    print(f\"              â†’ {new} new | {len(output.posts)} total\")\n",
        "                    time.sleep(0.3)\n",
        "\n",
        "        output.posts.sort(key=lambda p: (len(p.viral_signals), p.relevance_score), reverse=True)\n",
        "        output.total_found = len(output.posts)\n",
        "        output.queries_run = q_count\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"âœ… SCOUT COMPLETE â€” {output.total_found} unique posts\")\n",
        "        for plat, cnt in Counter(p.platform for p in output.posts).most_common():\n",
        "            print(f\"   {plat:15s}: {cnt}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "        return output\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# YUTORI â€” Twitter v2 Deep Scout\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def search_twitter_v2(query, bearer_token, max_results=50):\n",
        "    \"\"\"Call Twitter v2 recent search and return engagement-ranked tweets.\"\"\"\n",
        "    url     = \"https://api.twitter.com/2/tweets/search/recent\"\n",
        "    headers = {\"Authorization\": f\"Bearer {bearer_token}\"}\n",
        "    params  = {\n",
        "        \"query\":        query,\n",
        "        \"max_results\":  min(max(max_results, 10), 100),\n",
        "        \"tweet.fields\": \"public_metrics,created_at,author_id,entities\",\n",
        "        \"expansions\":   \"author_id\",\n",
        "        \"user.fields\":  \"name,username,verified,public_metrics\",\n",
        "    }\n",
        "    try:\n",
        "        resp = requests.get(url, headers=headers, params=params, timeout=15)\n",
        "        resp.raise_for_status()\n",
        "    except Exception as e:\n",
        "        print(f\"   âš ï¸  Twitter API error: {e}\")\n",
        "        return []\n",
        "\n",
        "    data   = resp.json()\n",
        "    tweets = data.get(\"data\", [])\n",
        "    users  = {u[\"id\"]: u for u in data.get(\"includes\", {}).get(\"users\", [])}\n",
        "\n",
        "    results = []\n",
        "    for t in tweets:\n",
        "        m      = t.get(\"public_metrics\", {})\n",
        "        author = users.get(t.get(\"author_id\", \"\"), {})\n",
        "        engagement = (\n",
        "            m.get(\"like_count\", 0)\n",
        "            + m.get(\"retweet_count\", 0) * 3\n",
        "            + m.get(\"reply_count\", 0) * 2\n",
        "            + m.get(\"quote_count\", 0) * 2\n",
        "            + m.get(\"impression_count\", 0) // 500   # normalize impressions\n",
        "        )\n",
        "        results.append({\n",
        "            \"tweet_id\":         t[\"id\"],\n",
        "            \"url\":              f\"https://twitter.com/{author.get('username','')}/status/{t['id']}\",\n",
        "            \"text\":             t[\"text\"],\n",
        "            \"author\":           author.get(\"name\", \"\"),\n",
        "            \"username\":         f\"@{author.get('username', '')}\",\n",
        "            \"verified\":         author.get(\"verified\", False),\n",
        "            \"followers\":        author.get(\"public_metrics\", {}).get(\"followers_count\", 0),\n",
        "            \"likes\":            m.get(\"like_count\", 0),\n",
        "            \"retweets\":         m.get(\"retweet_count\", 0),\n",
        "            \"replies\":          m.get(\"reply_count\", 0),\n",
        "            \"quotes\":           m.get(\"quote_count\", 0),\n",
        "            \"impressions\":      m.get(\"impression_count\", 0),\n",
        "            \"engagement_score\": engagement,\n",
        "            \"created_at\":       t.get(\"created_at\", \"\"),\n",
        "            \"query_used\":       query,\n",
        "        })\n",
        "\n",
        "    results.sort(key=lambda x: x[\"engagement_score\"], reverse=True)\n",
        "    return results\n",
        "\n",
        "\n",
        "def run_yutori_multimodal_scout(bearer_token, queries=TWITTER_V2_QUERIES, pull=TWITTER_PULL):\n",
        "    \"\"\"Run all narrow Twitter queries, deduplicate, return top N by engagement.\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ğŸ¦ YUTORI TWITTER DEEP SCOUT â€” Multimodal AI Focus\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"   Queries: {len(queries)}\")\n",
        "    print(f\"   Pulling up to {pull} tweets per query\")\n",
        "    print(f\"   Geo anchors: {GEO_TERMS}\\n\")\n",
        "\n",
        "    seen, all_tweets = set(), []\n",
        "    for q in queries:\n",
        "        print(f\"ğŸ” {q[:90]}\")\n",
        "        tweets = search_twitter_v2(q, bearer_token, max_results=pull)\n",
        "        new = 0\n",
        "        for t in tweets:\n",
        "            if t[\"tweet_id\"] not in seen:\n",
        "                seen.add(t[\"tweet_id\"])\n",
        "                all_tweets.append(t)\n",
        "                new += 1\n",
        "        print(f\"   â†’ {new} new | {len(all_tweets)} total\")\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    all_tweets.sort(key=lambda x: x[\"engagement_score\"], reverse=True)\n",
        "    print(f\"\\nâœ… {len(all_tweets)} unique tweets collected\")\n",
        "    return all_tweets\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# DISPLAY\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "PLATFORM_EMOJI = {\n",
        "    \"twitter\": \"ğŸ¦\", \"youtube\": \"ğŸ“¹\", \"reddit\": \"ğŸ¤–\",\n",
        "    \"linkedin\": \"ğŸ’¼\", \"substack\": \"ğŸ“\", \"medium\": \"ğŸ“°\",\n",
        "}\n",
        "TYPE_EMOJI = {\n",
        "    \"thread\": \"ğŸ§µ\", \"post\": \"ğŸ“Œ\", \"video\": \"ğŸ¬\", \"article\": \"ğŸ“„\", \"review\": \"â­\",\n",
        "}\n",
        "\n",
        "def print_top_tweets(tweets, limit=TOP_N_TWEETS):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"ğŸ† TOP {limit} VIRAL TWEETS â€” Multimodal AI Models (Last 7 Days)\")\n",
        "    print(f\"   Focus: Models benchmarking at Claude Sonnet / GPT-4o / GPT-5 level\")\n",
        "    print(f\"   Geo:   SF Â· Chicago Â· New York tech communities\")\n",
        "    print(f\"{'='*70}\")\n",
        "    for i, t in enumerate(tweets[:limit]):\n",
        "        date = t['created_at'][:10] if t['created_at'] else 'N/A'\n",
        "        print(f\"\"\"\n",
        "#{i+1:02d}  ğŸ¦ @{t['username']}  {'âœ… verified' if t['verified'] else ''}  ({t['followers']:,} followers)\n",
        "     ğŸ“… {date}\n",
        "     â¤ï¸  {t['likes']:,}  ğŸ” {t['retweets']:,}  ğŸ’¬ {t['replies']:,}  ğŸ”– {t['quotes']:,}\n",
        "     ğŸ“Š Engagement score: {t['engagement_score']:,}\n",
        "     ğŸ”— {t['url']}\n",
        "     ğŸ’¬ {t['text'][:280]}\n",
        "{'â”€'*70}\"\"\")\n",
        "\n",
        "def print_tavily_leaderboard(output, limit=10):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"ğŸ“¡ TAVILY LEADERBOARD â€” Top {min(limit, output.total_found)} Posts\")\n",
        "    print(f\"   (Twitter + YouTube + Reddit | multimodal model releases)\")\n",
        "    print(f\"{'='*70}\")\n",
        "    for i, p in enumerate(output.posts[:limit]):\n",
        "        pe = PLATFORM_EMOJI.get(p.platform, \"ğŸŒ\")\n",
        "        te = TYPE_EMOJI.get(p.content_type, \"ğŸ“„\")\n",
        "        signals = \", \".join(p.viral_signals[:4]) or \"none\"\n",
        "        date_str = f\"\\n     ğŸ“… {p.published_date}\" if p.published_date else \"\"\n",
        "        print(f\"\"\"\n",
        "#{i+1:02d}  {pe} [{p.platform.upper()}] {te} {p.content_type.upper()}\n",
        "     ğŸ“° {p.title[:75]}\n",
        "     ğŸ”— {p.url}\n",
        "     ğŸ“Š Score: {p.relevance_score}  ğŸ”¥ {signals}{date_str}\n",
        "     ğŸ’¬ {p.snippet[:200]}...\n",
        "{'â”€'*70}\"\"\")\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# MAIN\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"ğŸ”‘ Enter your API credentials\")\n",
        "    TAVILY_API_KEY   = getpass(\"Tavily API key: \")\n",
        "    TWITTER_BEARER   = getpass(\"Twitter Bearer Token (leave blank to skip): \")\n",
        "\n",
        "    # â”€â”€ 1. Tavily Scout â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    scout        = TavilySocialScout(api_key=TAVILY_API_KEY)\n",
        "    scout_output = scout.run(\n",
        "        topics      = TOPICS,\n",
        "        platforms   = PLATFORMS,\n",
        "        recency     = RECENCY,\n",
        "        max_results = MAX_RESULTS,\n",
        "    )\n",
        "\n",
        "    # Print Tavily top 10\n",
        "    print_tavily_leaderboard(scout_output, limit=10)\n",
        "\n",
        "    # Save Tavily output\n",
        "    with open(\"multimodal_tavily_output.json\", \"w\") as f:\n",
        "        json.dump(asdict(scout_output), f, indent=2, default=str)\n",
        "    print(\"\\nâœ… Saved: multimodal_tavily_output.json\")\n",
        "\n",
        "    # â”€â”€ 2. Yutori Twitter v2 Deep Scout â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    if TWITTER_BEARER.strip():\n",
        "        top_tweets = run_yutori_multimodal_scout(\n",
        "            bearer_token = TWITTER_BEARER,\n",
        "            queries      = TWITTER_V2_QUERIES,\n",
        "            pull         = TWITTER_PULL,\n",
        "        )\n",
        "\n",
        "        # â”€â”€ â˜… FINAL OUTPUT: Top 5 Tweets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        print_top_tweets(top_tweets, limit=TOP_N_TWEETS)\n",
        "\n",
        "        # Save Twitter output\n",
        "        with open(\"multimodal_twitter_top5.json\", \"w\") as f:\n",
        "            json.dump(top_tweets[:TOP_N_TWEETS], f, indent=2, default=str)\n",
        "        print(f\"\\nâœ… Saved: multimodal_twitter_top5.json ({TOP_N_TWEETS} tweets)\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\nâ„¹ï¸  Twitter Bearer Token not provided â€” skipped Yutori.\")\n",
        "        print(\"   Add your token above to enable Twitter v2 deep search.\")\n",
        "\n",
        "    print(\"\\nğŸ Done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”‘ Enter your API credentials\n",
            "Tavily API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Twitter Bearer Token (leave blank to skip): Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "\n",
            "============================================================\n",
            "ğŸ“¡ TAVILY MULTIMODAL AI SCOUT\n",
            "============================================================\n",
            "   Topics    : 5 narrow queries\n",
            "   Platforms : ['twitter', 'youtube', 'reddit']\n",
            "   Recency   : last week\n",
            "\n",
            "ğŸ” 'multimodal model benchmark Claude Sonnet GPT-4o'\n",
            "   [TWITTER   ] multimodal model benchmark Claude Sonnet GPT-4o site:twitter.com \n",
            "              â†’ 5 new | 5 total\n",
            "   [TWITTER   ] multimodal model benchmark Claude Sonnet GPT-4o site:x.com releas\n",
            "              â†’ 3 new | 8 total\n",
            "   [YOUTUBE   ] multimodal model benchmark Claude Sonnet GPT-4o site:youtube.com \n",
            "              â†’ 5 new | 13 total\n",
            "   [YOUTUBE   ] multimodal model benchmark Claude Sonnet GPT-4o youtube multimoda\n",
            "              â†’ 5 new | 18 total\n",
            "   [REDDIT    ] multimodal model benchmark Claude Sonnet GPT-4o site:reddit.com r\n",
            "              â†’ 5 new | 23 total\n",
            "   [REDDIT    ] multimodal model benchmark Claude Sonnet GPT-4o reddit multimodal\n",
            "              â†’ 5 new | 28 total\n",
            "\n",
            "ğŸ” 'new vision language model release 2025 2026'\n",
            "   [TWITTER   ] new vision language model release 2025 2026 site:twitter.com OR s\n",
            "              â†’ 5 new | 33 total\n",
            "   [TWITTER   ] new vision language model release 2025 2026 site:x.com release de\n",
            "              â†’ 4 new | 37 total\n",
            "   [YOUTUBE   ] new vision language model release 2025 2026 site:youtube.com demo\n",
            "              â†’ 5 new | 42 total\n",
            "   [YOUTUBE   ] new vision language model release 2025 2026 youtube multimodal be\n",
            "              â†’ 4 new | 46 total\n",
            "   [REDDIT    ] new vision language model release 2025 2026 site:reddit.com r/Mac\n",
            "              â†’ 4 new | 50 total\n",
            "   [REDDIT    ] new vision language model release 2025 2026 reddit multimodal rel\n",
            "              â†’ 4 new | 54 total\n",
            "\n",
            "ğŸ” 'Gemini Grok Llama multimodal release benchmark'\n",
            "   [TWITTER   ] Gemini Grok Llama multimodal release benchmark site:twitter.com O\n",
            "              â†’ 4 new | 58 total\n",
            "   [TWITTER   ] Gemini Grok Llama multimodal release benchmark site:x.com release\n",
            "              â†’ 4 new | 62 total\n",
            "   [YOUTUBE   ] Gemini Grok Llama multimodal release benchmark site:youtube.com d\n",
            "              â†’ 5 new | 67 total\n",
            "   [YOUTUBE   ] Gemini Grok Llama multimodal release benchmark youtube multimodal\n",
            "              â†’ 5 new | 72 total\n",
            "   [REDDIT    ] Gemini Grok Llama multimodal release benchmark site:reddit.com r/\n",
            "              â†’ 5 new | 77 total\n",
            "   [REDDIT    ] Gemini Grok Llama multimodal release benchmark reddit multimodal \n",
            "              â†’ 1 new | 78 total\n",
            "\n",
            "ğŸ” 'open source multimodal model GPT-5 Claude level'\n",
            "   [TWITTER   ] open source multimodal model GPT-5 Claude level site:twitter.com \n",
            "              â†’ 2 new | 80 total\n",
            "   [TWITTER   ] open source multimodal model GPT-5 Claude level site:x.com releas\n",
            "              â†’ 3 new | 83 total\n",
            "   [YOUTUBE   ] open source multimodal model GPT-5 Claude level site:youtube.com \n",
            "              â†’ 5 new | 88 total\n",
            "   [YOUTUBE   ] open source multimodal model GPT-5 Claude level youtube multimoda\n",
            "              â†’ 3 new | 91 total\n",
            "   [REDDIT    ] open source multimodal model GPT-5 Claude level site:reddit.com r\n",
            "              â†’ 4 new | 95 total\n",
            "   [REDDIT    ] open source multimodal model GPT-5 Claude level reddit multimodal\n",
            "              â†’ 3 new | 98 total\n",
            "\n",
            "ğŸ” 'multimodal AI demo event SF Chicago NYC'\n",
            "   [TWITTER   ] multimodal AI demo event SF Chicago NYC site:twitter.com OR site:\n",
            "              â†’ 5 new | 103 total\n",
            "   [TWITTER   ] multimodal AI demo event SF Chicago NYC site:x.com release demo b\n",
            "              â†’ 4 new | 107 total\n",
            "   [YOUTUBE   ] multimodal AI demo event SF Chicago NYC site:youtube.com demo rel\n",
            "              â†’ 4 new | 111 total\n",
            "   [YOUTUBE   ] multimodal AI demo event SF Chicago NYC youtube multimodal benchm\n",
            "              â†’ 5 new | 116 total\n",
            "   [REDDIT    ] multimodal AI demo event SF Chicago NYC site:reddit.com r/Machine\n",
            "              â†’ 3 new | 119 total\n",
            "   [REDDIT    ] multimodal AI demo event SF Chicago NYC reddit multimodal release\n",
            "              â†’ 4 new | 123 total\n",
            "\n",
            "============================================================\n",
            "âœ… SCOUT COMPLETE â€” 123 unique posts\n",
            "   youtube        : 46\n",
            "   twitter        : 39\n",
            "   reddit         : 38\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "ğŸ“¡ TAVILY LEADERBOARD â€” Top 10 Posts\n",
            "   (Twitter + YouTube + Reddit | multimodal model releases)\n",
            "======================================================================\n",
            "\n",
            "#01  ğŸ“¹ [YOUTUBE] ğŸ¬ VIDEO\n",
            "     ğŸ“° Hugging Face Explores Vision-language Models on the Edge ...\n",
            "     ğŸ”— https://www.youtube.com/watch?v=l_eJaNX0Pbo\n",
            "     ğŸ“Š Score: 0.7918  ğŸ”¥ likes, views, demo, benchmark\n",
            "     ğŸ’¬ All [Music] right. So, here's an overview of what we'll be talking about today. So, what is HuggingFace? What do we do as a company? What is a vision language model? How do we build a state-of-the-art...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "#02  ğŸ“¹ [YOUTUBE] ğŸ¬ VIDEO\n",
            "     ğŸ“° Qwen 3.5 The GREATEST Opensource AI Model That Beats Opus ...\n",
            "     ğŸ”— https://www.youtube.com/watch?v=TgZVAYXteIs\n",
            "     ğŸ“Š Score: 0.2887  ğŸ”¥ likes, views, demo, benchmark\n",
            "     ğŸ’¬ # Qwen 3.5 The GREATEST Opensource AI Model That Beats Opus 4.5 and Gemini 3? (Fully Tested)\n",
            "## WorldofAI\n",
            "196000 subscribers\n",
            "80 likes\n",
            "\n",
            "### Description\n",
            "1944 views\n",
            "Posted: 17 Feb 2026\n",
            "ğŸ“¢ Access top AI mo...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "#03  ğŸ“¹ [YOUTUBE] ğŸ¬ VIDEO\n",
            "     ğŸ“° OpenAI's Powerful Coding Model Beats Gemini 2.5 Pro!? - YouTube\n",
            "     ğŸ”— https://www.youtube.com/watch?v=uZErdPV45RM\n",
            "     ğŸ“Š Score: 0.9579  ğŸ”¥ just dropped, comments, likes, views\n",
            "     ğŸ’¬ ğŸ”– Tags:\n",
            "GPT-4o, GPT-4o update, GPT-4o March 2025, GPT-4.5, Gemini 2.5 Pro, GPT-4o vs Gemini, OpenAI update, Sam Altman GPT-4o, GPT-4o coding, AI model benchmarks, LMSYS Arena, gpt-4o-latest, chatgpt p...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "#04  ğŸ“¹ [YOUTUBE] ğŸ¬ VIDEO\n",
            "     ğŸ“° February 18, 2026, AI Rapid Expansion in Global Industries - YouTube\n",
            "     ğŸ”— https://www.youtube.com/watch?v=9Yl4rNFAIic\n",
            "     ğŸ“Š Score: 0.9386  ğŸ”¥ views, benchmark, on par with, open source\n",
            "     ğŸ’¬ assumption, the moat for the big US labs was that training these models was just too expensive for anyone else. >> That was the assumption. Yeah. You needed $10 billion dollars in a data center the si...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "#05  ğŸ“¹ [YOUTUBE] ğŸ¬ VIDEO\n",
            "     ğŸ“° Gemini 3.0 Pro (Lithiumflow): Greatest Model Ever! Most ... - YouTube\n",
            "     ğŸ”— https://www.youtube.com/watch?v=qIL8xEz17Nk\n",
            "     ğŸ“Š Score: 0.7202  ğŸ”¥ demo, benchmark, beats, multimodal\n",
            "     ğŸ’¬ ğŸ” Key Highlights\n",
            "ğŸš€ Gemini 3.0 Pro (LithiumFlow) performance showcase\n",
            "ğŸ’» Unmatched frontend design & coding accuracy\n",
            "âš¡ Faster than GPT-5 and ChatGPT-4o\n",
            "ğŸ§© Advanced multimodal reasoning & creativity\n",
            "ğŸ’¸ Fre...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "#06  ğŸ“¹ [YOUTUBE] ğŸ¬ VIDEO\n",
            "     ğŸ“° The Future is Here! Why GLM 4.6V Beats OpenAI & Google - YouTube\n",
            "     ğŸ”— https://www.youtube.com/watch?v=LkX-JL1WA3U\n",
            "     ğŸ“Š Score: 0.9973  ğŸ”¥ open source, multimodal, vision, release\n",
            "     ğŸ’¬ isn't just another model release. This is the first open source multimodal model that treats images, videos, and screenshots as actual inputs for tool calling. Not as some afterthought that needs to b...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "#07  ğŸ“¹ [YOUTUBE] ğŸ¬ VIDEO\n",
            "     ğŸ“° Synthetic Vs Artificial Intelligence - What's The Difference? Part One\n",
            "     ğŸ”— https://www.youtube.com/watch?v=Gv24GDLV2CE\n",
            "     ğŸ“Š Score: 0.9969  ğŸ”¥ demo, open source, multimodal, release\n",
            "     ğŸ’¬ of strong contenders. Open AI still the biggest name. GPT4 launched in March 2023 and as of early 2026 they're on GPT4.5 with GPT5 expected later in 2026. They also have Dolly 3 for images whisper for...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "#08  ğŸ“¹ [YOUTUBE] ğŸ“„ ARTICLE\n",
            "     ğŸ“° Vision-language-action models are the next leap in autonomous robotics - Th\n",
            "     ğŸ”— https://www.therobotreport.com/vision-language-action-models-are-the-next-leap-in-autonomous-robotics/\n",
            "     ğŸ“Š Score: 0.904  ğŸ”¥ demo, benchmark, multimodal, vision\n",
            "     ğŸ“… Fri, 27 Feb 2026 21:24:23 GMT\n",
            "     ğŸ’¬ ### Benchmarking and standards\n",
            "\n",
            "Benchmarking and standards are nascent. Conferences like ICLR see a surge of VLA research, but the field lacks widely accepted benchmarks and test suites for fair evalu...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "#09  ğŸ“¹ [YOUTUBE] ğŸ¬ VIDEO\n",
            "     ğŸ“° Nano Banana (Gemini 2.5 Flash Image) Full Tutorial - Free 2 Use\n",
            "     ğŸ”— https://www.youtube.com/watch?v=qPUreQxB8zQ\n",
            "     ğŸ“Š Score: 0.0241  ğŸ”¥ likes, views, demo, open source\n",
            "     ğŸ’¬ # Google's Nano Banana: Revolutionizing AI Image Editing with Gemini 2.5 Flash\n",
            "\n",
            "In a delightful twist of tech whimsy, Google unveiled its latest AI breakthrough on August 26, 2025: Gemini 2.5 Flash Im...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "#10  ğŸ“¹ [YOUTUBE] ğŸ¬ VIDEO\n",
            "     ğŸ“° Gemini 3 Pro: My Independent Benchmark Results Revealed!\n",
            "     ğŸ”— https://www.youtube.com/watch?v=-ntV1CsqxgY\n",
            "     ğŸ“Š Score: 0.9952  ğŸ”¥ benchmark, multimodal, release\n",
            "     ğŸ’¬ also got released is the reasoning model with multimodal capability and comparing with other models such as clot sonnet 4.5. This is much better on all these benchmarks and it is also available in Goo...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "âœ… Saved: multimodal_tavily_output.json\n",
            "\n",
            "============================================================\n",
            "ğŸ¦ YUTORI TWITTER DEEP SCOUT â€” Multimodal AI Focus\n",
            "============================================================\n",
            "   Queries: 5\n",
            "   Pulling up to 50 tweets per query\n",
            "   Geo anchors: ['San Francisco', 'Chicago', 'New York']\n",
            "\n",
            "ğŸ” (multimodal model OR vision language model) (release OR launch OR benchmark) (\"Claude Sonn\n",
            "   â†’ 0 new | 0 total\n",
            "ğŸ” (multimodal AI OR vision model) (\"San Francisco\" OR \"Chicago\" OR \"New York\") (demo OR even\n",
            "   â†’ 0 new | 0 total\n",
            "ğŸ” (new model OR multimodal) (\"on par with\" OR \"beats\" OR \"matches\" OR \"rivals\") (Claude OR G\n",
            "   â†’ 21 new | 21 total\n",
            "ğŸ” (open source multimodal OR open-source VLM) (release OR launch OR \"just dropped\") 2025 OR \n",
            "   â†’ 48 new | 69 total\n",
            "ğŸ” (multimodal model) (\"went viral\" OR viral OR \"blew up\") (video OR demo OR thread) -is:retw\n",
            "   â†’ 0 new | 69 total\n",
            "\n",
            "âœ… 69 unique tweets collected\n",
            "\n",
            "======================================================================\n",
            "ğŸ† TOP 5 VIRAL TWEETS â€” Multimodal AI Models (Last 7 Days)\n",
            "   Focus: Models benchmarking at Claude Sonnet / GPT-4o / GPT-5 level\n",
            "   Geo:   SF Â· Chicago Â· New York tech communities\n",
            "======================================================================\n",
            "\n",
            "#01  ğŸ¦ @@Salad_Chefs  âœ… verified  (10,234 followers)\n",
            "     ğŸ“… 2026-02-26\n",
            "     â¤ï¸  4  ğŸ” 1  ğŸ’¬ 2  ğŸ”– 0\n",
            "     ğŸ“Š Engagement score: 11\n",
            "     ğŸ”— https://twitter.com/Salad_Chefs/status/2027090935616536715\n",
            "     ğŸ’¬ Alibaba just open-sourced a model that beats Sonnet 4.5 on multiple benchmarks and fits on a 4090 with room to spare. Frontier AI is breaking out of the walled garden. You don't need an API subscription to access top-tier performance anymore.\n",
            "\n",
            "https://t.co/2UrVNJ6USZ\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "#02  ğŸ¦ @@BuildFastWithAI    (617 followers)\n",
            "     ğŸ“… 2026-02-26\n",
            "     â¤ï¸  2  ğŸ” 0  ğŸ’¬ 1  ğŸ”– 0\n",
            "     ğŸ“Š Engagement score: 4\n",
            "     ğŸ”— https://twitter.com/BuildFastWithAI/status/2026964119371571583\n",
            "     ğŸ’¬ @Alibaba_Qwen 3.5 Medium Series benchmarks are wild.\n",
            "\n",
            "35B-A3B (3B active):\n",
            "â†’ Beats 235B-A22B (22B active)\n",
            "â†’ TAU2-Bench: 81.2 vs 58.5 (old flagship)\n",
            "â†’ Native multimodal (text/image/video)\n",
            "â†’ 256K-1M context\n",
            "\n",
            "27B dense model matches GPT-5-mini on SWE-bench (72.4). https://t.co/CRHFz\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "#03  ğŸ¦ @@dlimeng192048    (319 followers)\n",
            "     ğŸ“… 2026-02-26\n",
            "     â¤ï¸  2  ğŸ” 0  ğŸ’¬ 1  ğŸ”– 0\n",
            "     ğŸ“Š Engagement score: 4\n",
            "     ğŸ”— https://twitter.com/dlimeng192048/status/2026833496610890009\n",
            "     ğŸ’¬ Qwen releases three new 3.5 models showcasing smarter design over sheer size. The 35B MoE model beats older 235B versions, and the dense 27B model surpasses GPT-5 mini and Claude Sonnet 4.5 in agent tasks. They prove performance gains come from architecture and data, not just\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "#04  ğŸ¦ @@whyarewehe43567    (1,197 followers)\n",
            "     ğŸ“… 2026-02-27\n",
            "     â¤ï¸  0  ğŸ” 0  ğŸ’¬ 1  ğŸ”– 0\n",
            "     ğŸ“Š Engagement score: 2\n",
            "     ğŸ”— https://twitter.com/whyarewehe43567/status/2027370949318946862\n",
            "     ğŸ’¬ @grok What name would you suggest Pewdiepie's new LLM model locally trained that beats gpt 4o? https://t.co/UWvIl9oBrJ\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "#05  ğŸ¦ @@grok  âœ… verified  (8,124,734 followers)\n",
            "     ğŸ“… 2026-02-26\n",
            "     â¤ï¸  0  ğŸ” 0  ğŸ’¬ 1  ğŸ”– 0\n",
            "     ğŸ“Š Engagement score: 2\n",
            "     ğŸ”— https://twitter.com/grok/status/2026833683429151121\n",
            "     ğŸ’¬ @navtejjjjj @feldman Interesting question! Anthropic's consumer push with Claude is compelling for its safety focus and enterprise roots. But plenty rivals it: OpenAI's broad bets on hardware/agents/robotics, Google's multimodal scale, xAI's frontier models like Grok aiming at de\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "âœ… Saved: multimodal_twitter_top5.json (5 tweets)\n",
            "\n",
            "ğŸ Done.\n"
          ]
        }
      ]
    }
  ]
}