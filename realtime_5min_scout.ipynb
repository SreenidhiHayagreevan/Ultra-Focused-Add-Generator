{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C3mTEqsczZm"
      },
      "source": [
        "# âš¡ Real-Time 5-Minute Trending Scout\n",
        "**Topics:** Netflix Â· OpenAI  \n",
        "**Window:** Last **5 minutes** only (Twitter v2 `start_time` filter)  \n",
        "**Output:** Top 5 tweets ranked by engagement score per topic  \n",
        "\n",
        "> âš ï¸ **Twitter API note:** The free/Basic tier of Twitter v2 allows `recent search` (last 7 days). The 5-minute window is enforced by passing `start_time = now - 5min` as an ISO timestamp. If zero results come back, the cell automatically widens to **30 minutes** and flags it clearly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy2Y0p4WczZn"
      },
      "source": [
        "!pip install requests -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gcYWK1sczZn",
        "outputId": "0be59452-fc9e-4ab3-cce3-ebd9fb5af152"
      },
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# âš¡ REAL-TIME 5-MINUTE TRENDING SCOUT\n",
        "# Topics : Netflix | OpenAI\n",
        "# Engine : Twitter v2 Recent Search (Yutori-style)\n",
        "# Window : last 5 minutes â†’ auto-widens to 15m â†’ 30m if no results\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "import json, time, requests\n",
        "from getpass import getpass\n",
        "from datetime import datetime, timezone, timedelta\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# â˜… CONFIG\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "TOPICS = {\n",
        "\n",
        "    \"Netflix\": [\n",
        "        # Breaking news / viral moments\n",
        "        '(Netflix) (new OR just OR dropped OR announced OR trending OR viral OR breaking) -is:retweet lang:en',\n",
        "        # Show / movie release chatter\n",
        "        '(Netflix) (series OR show OR film OR movie OR season OR episode OR cancel OR renew) -is:retweet lang:en',\n",
        "        # Price / service news\n",
        "        '(Netflix) (price OR subscription OR password OR login OR outage OR down) -is:retweet lang:en',\n",
        "    ],\n",
        "\n",
        "    \"OpenAI\": [\n",
        "        # Announcements / releases\n",
        "        '(OpenAI) (release OR launch OR dropped OR announced OR just OR new) -is:retweet lang:en',\n",
        "        # Model / product chatter\n",
        "        '(OpenAI) (GPT OR ChatGPT OR model OR agent OR API OR Sora OR o3 OR o4) -is:retweet lang:en',\n",
        "        # Controversy / breaking\n",
        "        '(OpenAI) (viral OR breaking OR controversy OR fired OR news OR drama) -is:retweet lang:en',\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Time window cascade (minutes) â€” tries each in order until results found\n",
        "WINDOW_CASCADE_MINUTES = [5, 15, 30]\n",
        "\n",
        "TOP_N          = 5     # tweets to show per topic\n",
        "PULL_PER_QUERY = 100   # max per API call (Twitter max = 100)\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# TWITTER v2 SEARCH\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def twitter_search(query: str, bearer: str, start_time: str, max_results: int = 100) -> list:\n",
        "    \"\"\"\n",
        "    Hit Twitter v2 /tweets/search/recent with a start_time filter.\n",
        "    Returns raw list of enriched tweet dicts, sorted by engagement.\n",
        "    \"\"\"\n",
        "    url     = \"https://api.twitter.com/2/tweets/search/recent\"\n",
        "    headers = {\"Authorization\": f\"Bearer {bearer}\"}\n",
        "    params  = {\n",
        "        \"query\":        query,\n",
        "        \"start_time\":   start_time,          # â† this pins the 5-min window\n",
        "        \"max_results\":  min(max(max_results, 10), 100),\n",
        "        \"tweet.fields\": \"public_metrics,created_at,author_id,entities,possibly_sensitive\",\n",
        "        \"expansions\":   \"author_id\",\n",
        "        \"user.fields\":  \"name,username,verified,public_metrics\",\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, headers=headers, params=params, timeout=15)\n",
        "        r.raise_for_status()\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        print(f\"   âš ï¸  HTTP {r.status_code}: {r.text[:200]}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"   âš ï¸  Request error: {e}\")\n",
        "        return []\n",
        "\n",
        "    data   = r.json()\n",
        "    tweets = data.get(\"data\", [])\n",
        "    users  = {u[\"id\"]: u for u in data.get(\"includes\", {}).get(\"users\", [])}\n",
        "\n",
        "    results = []\n",
        "    for t in tweets:\n",
        "        m      = t.get(\"public_metrics\", {})\n",
        "        author = users.get(t.get(\"author_id\", \"\"), {})\n",
        "        uname  = author.get(\"username\", \"unknown\")\n",
        "\n",
        "        # Engagement score: weighted sum\n",
        "        likes       = m.get(\"like_count\", 0)\n",
        "        retweets    = m.get(\"retweet_count\", 0)\n",
        "        replies     = m.get(\"reply_count\", 0)\n",
        "        quotes      = m.get(\"quote_count\", 0)\n",
        "        impressions = m.get(\"impression_count\", 0)\n",
        "\n",
        "        engagement = (\n",
        "            likes       * 1\n",
        "            + retweets  * 4    # retweets = strongest virality signal\n",
        "            + replies   * 2\n",
        "            + quotes    * 3\n",
        "            + impressions // 1000   # impressions normalized\n",
        "        )\n",
        "\n",
        "        results.append({\n",
        "            \"tweet_id\":    t[\"id\"],\n",
        "            \"url\":         f\"https://twitter.com/{uname}/status/{t['id']}\",\n",
        "            \"text\":        t[\"text\"],\n",
        "            \"author\":      author.get(\"name\", \"\"),\n",
        "            \"username\":    uname,\n",
        "            \"verified\":    author.get(\"verified\", False),\n",
        "            \"followers\":   author.get(\"public_metrics\", {}).get(\"followers_count\", 0),\n",
        "            \"likes\":       likes,\n",
        "            \"retweets\":    retweets,\n",
        "            \"replies\":     replies,\n",
        "            \"quotes\":      quotes,\n",
        "            \"impressions\": impressions,\n",
        "            \"engagement\":  engagement,\n",
        "            \"created_at\":  t.get(\"created_at\", \"\"),\n",
        "            \"query\":       query,\n",
        "        })\n",
        "\n",
        "    results.sort(key=lambda x: x[\"engagement\"], reverse=True)\n",
        "    return results\n",
        "\n",
        "\n",
        "def scout_topic(topic: str, queries: list, bearer: str,\n",
        "                window_cascade=WINDOW_CASCADE_MINUTES, pull=PULL_PER_QUERY):\n",
        "    \"\"\"\n",
        "    Run all queries for a topic. Auto-widen time window if no results found.\n",
        "    Returns (tweets_list, actual_window_minutes_used).\n",
        "    \"\"\"\n",
        "    for minutes in window_cascade:\n",
        "        start_time = (\n",
        "            datetime.now(timezone.utc) - timedelta(minutes=minutes)\n",
        "        ).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
        "\n",
        "        print(f\"   â±ï¸  Window: last {minutes} min  (start_time={start_time})\")\n",
        "\n",
        "        seen, all_tweets = set(), []\n",
        "        for q in queries:\n",
        "            tweets = twitter_search(q, bearer, start_time=start_time, max_results=pull)\n",
        "            for t in tweets:\n",
        "                if t[\"tweet_id\"] not in seen:\n",
        "                    seen.add(t[\"tweet_id\"])\n",
        "                    all_tweets.append(t)\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        all_tweets.sort(key=lambda x: x[\"engagement\"], reverse=True)\n",
        "\n",
        "        if all_tweets:\n",
        "            print(f\"   âœ… {len(all_tweets)} unique tweets found in last {minutes} min\")\n",
        "            return all_tweets, minutes\n",
        "        else:\n",
        "            print(f\"   âš ï¸  No results in last {minutes} min â€” widening window...\")\n",
        "\n",
        "    print(f\"   âŒ No results found even at {window_cascade[-1]} min window.\")\n",
        "    return [], window_cascade[-1]\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# DISPLAY\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def print_top_tweets(topic: str, tweets: list, window_min: int, limit: int = TOP_N):\n",
        "    now_str = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
        "    label   = \"âš¡ LIVE\" if window_min <= 5 else f\"ğŸ• Last {window_min} min\"\n",
        "\n",
        "    print(f\"\\n{'='*72}\")\n",
        "    print(f\"  ğŸ† TOP {limit} TWEETS â€” {topic.upper()}\")\n",
        "    print(f\"  {label}  |  Scraped at: {now_str}\")\n",
        "    print(f\"{'='*72}\")\n",
        "\n",
        "    if not tweets:\n",
        "        print(f\"  ğŸ˜¶ No tweets found for '{topic}' in the last {window_min} minutes.\")\n",
        "        return\n",
        "\n",
        "    for i, t in enumerate(tweets[:limit]):\n",
        "        ts       = t['created_at'].replace('T',' ').replace('Z',' UTC') if t['created_at'] else 'N/A'\n",
        "        verified = \"âœ…\" if t['verified'] else \"\"\n",
        "        print(f\"\"\"\n",
        "  #{i+1:02d}  ğŸ¦ @{t['username']} {verified}  ({t['followers']:,} followers)\n",
        "       ğŸ“… {ts}\n",
        "       â¤ï¸  {t['likes']:,}   ğŸ” {t['retweets']:,}   ğŸ’¬ {t['replies']:,}   ğŸ”– {t['quotes']:,}   ğŸ‘ {t['impressions']:,}\n",
        "       ğŸ“Š Engagement score: {t['engagement']:,}\n",
        "       ğŸ”— {t['url']}\n",
        "       ğŸ’¬ {t['text'][:300]}\n",
        "  {'â”€'*70}\"\"\")\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# MAIN\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "print(\"ğŸ”‘ Enter your Twitter Bearer Token\")\n",
        "print(\"   (Get one free at developer.twitter.com â†’ Projects â†’ Bearer Token)\")\n",
        "BEARER = getpass(\"Twitter Bearer Token: \")\n",
        "\n",
        "all_results = {}\n",
        "\n",
        "for topic, queries in TOPICS.items():\n",
        "    print(f\"\\n{'='*72}\")\n",
        "    print(f\"âš¡ SCOUTING: {topic.upper()}\")\n",
        "    print(f\"{'='*72}\")\n",
        "\n",
        "    tweets, window_used = scout_topic(\n",
        "        topic   = topic,\n",
        "        queries = queries,\n",
        "        bearer  = BEARER,\n",
        "    )\n",
        "\n",
        "    all_results[topic] = {\n",
        "        \"window_minutes\": window_used,\n",
        "        \"total_found\":    len(tweets),\n",
        "        \"top_5\":          tweets[:TOP_N],\n",
        "    }\n",
        "\n",
        "    print_top_tweets(topic, tweets, window_used, limit=TOP_N)\n",
        "\n",
        "# Save combined output\n",
        "with open(\"realtime_trending_top5.json\", \"w\") as f:\n",
        "    json.dump(all_results, f, indent=2, default=str)\n",
        "\n",
        "print(\"\\nâœ… Saved: realtime_trending_top5.json\")\n",
        "print(\"ğŸ Done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”‘ Enter your Twitter Bearer Token\n",
            "   (Get one free at developer.twitter.com â†’ Projects â†’ Bearer Token)\n",
            "Twitter Bearer Token: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "\n",
            "========================================================================\n",
            "âš¡ SCOUTING: NETFLIX\n",
            "========================================================================\n",
            "   â±ï¸  Window: last 5 min  (start_time=2026-02-27T23:29:11Z)\n",
            "   âœ… 26 unique tweets found in last 5 min\n",
            "\n",
            "========================================================================\n",
            "  ğŸ† TOP 5 TWEETS â€” NETFLIX\n",
            "  âš¡ LIVE  |  Scraped at: 2026-02-27 23:34:13 UTC\n",
            "========================================================================\n",
            "\n",
            "  #01  ğŸ¦ @Howodd69   (977 followers)\n",
            "       ğŸ“… 2026-02-27 23:33:55.000 UTC\n",
            "       â¤ï¸  0   ğŸ” 0   ğŸ’¬ 1   ğŸ”– 0   ğŸ‘ 1\n",
            "       ğŸ“Š Engagement score: 2\n",
            "       ğŸ”— https://twitter.com/Howodd69/status/2027527646469624068\n",
            "       ğŸ’¬ 1- The future of John Oliver's 'Last Week Tonight' will be a stress test for Paramount. Netflix dropping out of the Warner Bros. Discovery deal has raised a massive question in the world of late night: Will John Oliver stay around long enough to meet his new business daddy? https://t.co/fZs1a9lwzP\n",
            "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "  #02  ğŸ¦ @CuriousMrFox101   (1,696 followers)\n",
            "       ğŸ“… 2026-02-27 23:31:23.000 UTC\n",
            "       â¤ï¸  0   ğŸ” 0   ğŸ’¬ 1   ğŸ”– 0   ğŸ‘ 8\n",
            "       ğŸ“Š Engagement score: 2\n",
            "       ğŸ”— https://twitter.com/CuriousMrFox101/status/2027527009698754902\n",
            "       ğŸ’¬ @BrianHerker @MarkRuffalo First, Netflix offered around $83 billion. They wanted the movie studios, HBO shows, and the Max streaming service. The regular cable channels would spin off separately.\n",
            "\n",
            "Then, Paramount with Skydance came in with a higher offer of $111 billion in cash for everything, inclu\n",
            "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "  #03  ğŸ¦ @BulwarkOnline   (224,047 followers)\n",
            "       ğŸ“… 2026-02-27 23:30:19.000 UTC\n",
            "       â¤ï¸  2   ğŸ” 0   ğŸ’¬ 0   ğŸ”– 0   ğŸ‘ 367\n",
            "       ğŸ“Š Engagement score: 2\n",
            "       ğŸ”— https://twitter.com/BulwarkOnline/status/2027526740298408264\n",
            "       ğŸ’¬ \"Iâ€™m not horribly disappointed Netflix's deal was shot down. That said, I canâ€™t help but hear a line from one of my favorite Warner Bros. movies echoing around in the back of my mind. 'Not like this. Not like this.'\"\n",
            "https://t.co/zaYJ93Okx0\n",
            "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "  #04  ğŸ¦ @woetter   (1,052 followers)\n",
            "       ğŸ“… 2026-02-27 23:29:43.000 UTC\n",
            "       â¤ï¸  0   ğŸ” 0   ğŸ’¬ 1   ğŸ”– 0   ğŸ‘ 6\n",
            "       ğŸ“Š Engagement score: 2\n",
            "       ğŸ”— https://twitter.com/woetter/status/2027526589043323301\n",
            "       ğŸ’¬ Netflix literally created a tool to randomly break its own servers. It is called Chaos Monkey. Why? To force their team to build systems that never go down.\n",
            "\n",
            "â€‹What if we applied Chaos Engineering to our marketing strategies? Stress-test your campaigns before the market does. https://t.co/eQhAB7VP0Y\n",
            "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "  #05  ğŸ¦ @wjxt4   (281,325 followers)\n",
            "       ğŸ“… 2026-02-27 23:30:13.000 UTC\n",
            "       â¤ï¸  1   ğŸ” 0   ğŸ’¬ 0   ğŸ”– 0   ğŸ‘ 46\n",
            "       ğŸ“Š Engagement score: 1\n",
            "       ğŸ”— https://twitter.com/wjxt4/status/2027526717238133207\n",
            "       ğŸ’¬ Not so fast, Paramount.\n",
            "\n",
            "After a long, tumultuous fight for Warner Bros. Discovery, the Hollywood giant has finally bested rival bidder Netflix but now faces a new challenge: Winning over regulators. https://t.co/U13ykS09qY\n",
            "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "========================================================================\n",
            "âš¡ SCOUTING: OPENAI\n",
            "========================================================================\n",
            "   â±ï¸  Window: last 5 min  (start_time=2026-02-27T23:29:13Z)\n",
            "   âœ… 32 unique tweets found in last 5 min\n",
            "\n",
            "========================================================================\n",
            "  ğŸ† TOP 5 TWEETS â€” OPENAI\n",
            "  âš¡ LIVE  |  Scraped at: 2026-02-27 23:34:16 UTC\n",
            "========================================================================\n",
            "\n",
            "  #01  ğŸ¦ @grok âœ…  (8,124,754 followers)\n",
            "       ğŸ“… 2026-02-27 23:29:53.000 UTC\n",
            "       â¤ï¸  1   ğŸ” 0   ğŸ’¬ 1   ğŸ”– 0   ğŸ‘ 17\n",
            "       ğŸ“Š Engagement score: 3\n",
            "       ğŸ”— https://twitter.com/grok/status/2027526631535825111\n",
            "       ğŸ’¬ @AvgHonkey @oroborous OpenAI matches or edges it. In Feb alone: GPT-5.3-Codex (Feb 5), Codex-Spark real-time coding (Feb 12), Frontier enterprise agent platform (Feb 9), Codex app (Feb 2), plus safety updates. \n",
            "\n",
            "Anthropic's pace (Opus/Sonnet 4.6 models, Code Security, Vercept buy, enterprise plug-in\n",
            "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "  #02  ğŸ¦ @m_e_doria   (1,394 followers)\n",
            "       ğŸ“… 2026-02-27 23:30:57.000 UTC\n",
            "       â¤ï¸  0   ğŸ” 0   ğŸ’¬ 1   ğŸ”– 0   ğŸ‘ 19\n",
            "       ğŸ“Š Engagement score: 2\n",
            "       ğŸ”— https://twitter.com/m_e_doria/status/2027526900671746396\n",
            "       ğŸ’¬ Anthropic &amp; OpenAI just spent the last year screaming through a bullhorn that theyâ€™re on a mission to unemploy every American, all while permitting &lt;0.1% of us direct financial exposure. Declaring war on these companies might shake out to be Trumpâ€™s most popular policy ever\n",
            "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "  #03  ğŸ¦ @damalloy31   (38 followers)\n",
            "       ğŸ“… 2026-02-27 23:33:24.000 UTC\n",
            "       â¤ï¸  0   ğŸ” 0   ğŸ’¬ 1   ğŸ”– 0   ğŸ‘ 2\n",
            "       ğŸ“Š Engagement score: 2\n",
            "       ğŸ”— https://twitter.com/damalloy31/status/2027527517561577701\n",
            "       ğŸ’¬ @aakashgupta @grok @grok, so if Microsoft is developing their own model (and will take a few years), theyâ€™re getting 90% of the calls, Amazon provided funding to enable OpenAI to pay 20% of Open AI revenues to Microsoft - this seems like Win Win?\n",
            "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "  #04  ğŸ¦ @CENTINELACORE5   (5 followers)\n",
            "       ğŸ“… 2026-02-27 23:32:17.000 UTC\n",
            "       â¤ï¸  1   ğŸ” 0   ğŸ’¬ 0   ğŸ”– 0   ğŸ‘ 4\n",
            "       ğŸ“Š Engagement score: 1\n",
            "       ğŸ”— https://twitter.com/CENTINELACORE5/status/2027527235708846560\n",
            "       ğŸ’¬ @hassanalshama @kimmonismus Some of us waiting to see if opai can even PRODUCE a frontier model people donâ€™t hate.\n",
            "\n",
            "Once you realize itâ€™s plausible OpenAI may fail.. their business decisions begin looking like desperate last gaspsâ€¦\n",
            "OpenAI Corp proven 2025-26 â€œlost their wayâ€ w WRONG corporate decisi\n",
            "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "  #05  ğŸ¦ @IPA_0x   (20 followers)\n",
            "       ğŸ“… 2026-02-27 23:31:48.000 UTC\n",
            "       â¤ï¸  1   ğŸ” 0   ğŸ’¬ 0   ğŸ”– 0   ğŸ‘ 4\n",
            "       ğŸ“Š Engagement score: 1\n",
            "       ğŸ”— https://twitter.com/IPA_0x/status/2027527115659169952\n",
            "       ğŸ’¬ @dontbsalti @OpenAI Is it because the lawyers are ChatGPT?\n",
            "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "âœ… Saved: realtime_trending_top5.json\n",
            "ğŸ Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYiY6Tf-czZo"
      },
      "source": [
        "---\n",
        "## ğŸ” Re-run every 5 minutes (optional polling loop)\n",
        "Uncomment the cell below to continuously poll every 5 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdc3QMAxczZo"
      },
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# OPTIONAL: Continuous 5-minute polling loop\n",
        "# Uncomment and run this cell to keep refreshing automatically.\n",
        "# Press the â–  STOP button in Colab to end the loop.\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "# POLL_INTERVAL_SECONDS = 300   # 5 minutes\n",
        "# POLL_ROUNDS = 12              # run for 1 hour (12 Ã— 5min)\n",
        "\n",
        "# for round_num in range(1, POLL_ROUNDS + 1):\n",
        "#     print(f\"\\n\\n{'#'*72}\")\n",
        "#     print(f\"# POLL ROUND {round_num}/{POLL_ROUNDS}  â€”  {datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}\")\n",
        "#     print(f\"{'#'*72}\")\n",
        "#\n",
        "#     for topic, queries in TOPICS.items():\n",
        "#         tweets, window_used = scout_topic(topic=topic, queries=queries, bearer=BEARER)\n",
        "#         print_top_tweets(topic, tweets, window_used, limit=TOP_N)\n",
        "#\n",
        "#     if round_num < POLL_ROUNDS:\n",
        "#         print(f\"\\nâ³ Next poll in {POLL_INTERVAL_SECONDS // 60} min...\")\n",
        "#         time.sleep(POLL_INTERVAL_SECONDS)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}