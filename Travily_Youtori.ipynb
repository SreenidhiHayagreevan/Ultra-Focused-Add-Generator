{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tavily-python requests beautifulsoup4 -q"
      ],
      "metadata": {
        "id": "RqB9E2DxHD91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5SXuf7N7qCZ",
        "outputId": "3992e96d-fbd0-4017-89dc-adf7eed8e106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tavily API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "\n",
            "============================================================\n",
            "ðŸ“¡ TAVILY SOCIAL SCOUT\n",
            "============================================================\n",
            "   Topics    : ['OpenAI agents', 'Claude AI', 'Google Gemini', 'AWS Bedrock', 'GCP Vertex AI', 'agentic AI platform']\n",
            "   Platforms : ['twitter', 'linkedin', 'reddit', 'youtube', 'blogs']\n",
            "   Recency   : last day\n",
            "\n",
            "ðŸ”Ž Topic: 'OpenAI agents'\n",
            "   [TWITTER   ] OpenAI agents site:twitter.com viral thread 2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-880/3653994553.py:73: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  timestamp:         str       = field(default_factory=lambda: datetime.utcnow().isoformat())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              â†’ 5 new | 5 total\n",
            "   [TWITTER   ] OpenAI agents site:x.com trending\n",
            "              â†’ 5 new | 10 total\n",
            "   [LINKEDIN  ] OpenAI agents site:linkedin.com CEO founder post viral\n",
            "              â†’ 2 new | 12 total\n",
            "   [LINKEDIN  ] OpenAI agents linkedin.com/posts reactions comments\n",
            "              â†’ 5 new | 17 total\n",
            "   [REDDIT    ] OpenAI agents site:reddit.com upvotes hot 2025\n",
            "              â†’ 5 new | 22 total\n",
            "   [REDDIT    ] OpenAI agents reddit r/MachineLearning OR r/technology OR r/Local\n",
            "              â†’ 3 new | 25 total\n",
            "   [YOUTUBE   ] OpenAI agents site:youtube.com review demo 2025\n",
            "              â†’ 5 new | 30 total\n",
            "   [YOUTUBE   ] OpenAI agents youtube.com viral video breakdown\n",
            "              â†’ 4 new | 34 total\n",
            "   [BLOGS     ] OpenAI agents site:substack.com 2025\n",
            "              â†’ 5 new | 39 total\n",
            "   [BLOGS     ] OpenAI agents site:medium.com review analysis 2025\n",
            "              â†’ 5 new | 44 total\n",
            "\n",
            "ðŸ”Ž Topic: 'Claude AI'\n",
            "   [TWITTER   ] Claude AI site:twitter.com viral thread 2025\n",
            "              â†’ 4 new | 48 total\n",
            "   [TWITTER   ] Claude AI site:x.com trending\n",
            "              â†’ 5 new | 53 total\n",
            "   [LINKEDIN  ] Claude AI site:linkedin.com CEO founder post viral\n",
            "              â†’ 0 new | 53 total\n",
            "   [LINKEDIN  ] Claude AI linkedin.com/posts reactions comments\n",
            "              â†’ 5 new | 58 total\n",
            "   [REDDIT    ] Claude AI site:reddit.com upvotes hot 2025\n",
            "              â†’ 5 new | 63 total\n",
            "   [REDDIT    ] Claude AI reddit r/MachineLearning OR r/technology OR r/LocalLLaM\n",
            "              â†’ 2 new | 65 total\n",
            "   [YOUTUBE   ] Claude AI site:youtube.com review demo 2025\n",
            "              â†’ 5 new | 70 total\n",
            "   [YOUTUBE   ] Claude AI youtube.com viral video breakdown\n",
            "              â†’ 1 new | 71 total\n",
            "   [BLOGS     ] Claude AI site:substack.com 2025\n",
            "              â†’ 5 new | 76 total\n",
            "   [BLOGS     ] Claude AI site:medium.com review analysis 2025\n",
            "              â†’ 5 new | 81 total\n",
            "\n",
            "ðŸ”Ž Topic: 'Google Gemini'\n",
            "   [TWITTER   ] Google Gemini site:twitter.com viral thread 2025\n",
            "              â†’ 4 new | 85 total\n",
            "   [TWITTER   ] Google Gemini site:x.com trending\n",
            "              â†’ 5 new | 90 total\n",
            "   [LINKEDIN  ] Google Gemini site:linkedin.com CEO founder post viral\n",
            "              â†’ 0 new | 90 total\n",
            "   [LINKEDIN  ] Google Gemini linkedin.com/posts reactions comments\n",
            "              â†’ 5 new | 95 total\n",
            "   [REDDIT    ] Google Gemini site:reddit.com upvotes hot 2025\n",
            "              â†’ 5 new | 100 total\n",
            "   [REDDIT    ] Google Gemini reddit r/MachineLearning OR r/technology OR r/Local\n",
            "              â†’ 2 new | 102 total\n",
            "   [YOUTUBE   ] Google Gemini site:youtube.com review demo 2025\n",
            "              â†’ 5 new | 107 total\n",
            "   [YOUTUBE   ] Google Gemini youtube.com viral video breakdown\n",
            "              â†’ 1 new | 108 total\n",
            "   [BLOGS     ] Google Gemini site:substack.com 2025\n",
            "              â†’ 5 new | 113 total\n",
            "   [BLOGS     ] Google Gemini site:medium.com review analysis 2025\n",
            "              â†’ 5 new | 118 total\n",
            "\n",
            "ðŸ”Ž Topic: 'AWS Bedrock'\n",
            "   [TWITTER   ] AWS Bedrock site:twitter.com viral thread 2025\n",
            "              â†’ 5 new | 123 total\n",
            "   [TWITTER   ] AWS Bedrock site:x.com trending\n",
            "              â†’ 5 new | 128 total\n",
            "   [LINKEDIN  ] AWS Bedrock site:linkedin.com CEO founder post viral\n",
            "              â†’ 0 new | 128 total\n",
            "   [LINKEDIN  ] AWS Bedrock linkedin.com/posts reactions comments\n",
            "              â†’ 5 new | 133 total\n",
            "   [REDDIT    ] AWS Bedrock site:reddit.com upvotes hot 2025\n",
            "              â†’ 5 new | 138 total\n",
            "   [REDDIT    ] AWS Bedrock reddit r/MachineLearning OR r/technology OR r/LocalLL\n",
            "              â†’ 3 new | 141 total\n",
            "   [YOUTUBE   ] AWS Bedrock site:youtube.com review demo 2025\n",
            "              â†’ 5 new | 146 total\n",
            "   [YOUTUBE   ] AWS Bedrock youtube.com viral video breakdown\n",
            "              â†’ 3 new | 149 total\n",
            "   [BLOGS     ] AWS Bedrock site:substack.com 2025\n",
            "              â†’ 5 new | 154 total\n",
            "   [BLOGS     ] AWS Bedrock site:medium.com review analysis 2025\n",
            "              â†’ 5 new | 159 total\n",
            "\n",
            "ðŸ”Ž Topic: 'GCP Vertex AI'\n",
            "   [TWITTER   ] GCP Vertex AI site:twitter.com viral thread 2025\n",
            "              â†’ 4 new | 163 total\n",
            "   [TWITTER   ] GCP Vertex AI site:x.com trending\n",
            "              â†’ 4 new | 167 total\n",
            "   [LINKEDIN  ] GCP Vertex AI site:linkedin.com CEO founder post viral\n",
            "              â†’ 0 new | 167 total\n",
            "   [LINKEDIN  ] GCP Vertex AI linkedin.com/posts reactions comments\n",
            "              â†’ 3 new | 170 total\n",
            "   [REDDIT    ] GCP Vertex AI site:reddit.com upvotes hot 2025\n",
            "              â†’ 5 new | 175 total\n",
            "   [REDDIT    ] GCP Vertex AI reddit r/MachineLearning OR r/technology OR r/Local\n",
            "              â†’ 2 new | 177 total\n",
            "   [YOUTUBE   ] GCP Vertex AI site:youtube.com review demo 2025\n",
            "              â†’ 5 new | 182 total\n",
            "   [YOUTUBE   ] GCP Vertex AI youtube.com viral video breakdown\n",
            "              â†’ 2 new | 184 total\n",
            "   [BLOGS     ] GCP Vertex AI site:substack.com 2025\n",
            "              â†’ 5 new | 189 total\n",
            "   [BLOGS     ] GCP Vertex AI site:medium.com review analysis 2025\n",
            "              â†’ 5 new | 194 total\n",
            "\n",
            "ðŸ”Ž Topic: 'agentic AI platform'\n",
            "   [TWITTER   ] agentic AI platform site:twitter.com viral thread 2025\n",
            "              â†’ 3 new | 197 total\n",
            "   [TWITTER   ] agentic AI platform site:x.com trending\n",
            "              â†’ 5 new | 202 total\n",
            "   [LINKEDIN  ] agentic AI platform site:linkedin.com CEO founder post viral\n",
            "              â†’ 0 new | 202 total\n",
            "   [LINKEDIN  ] agentic AI platform linkedin.com/posts reactions comments\n",
            "              â†’ 4 new | 206 total\n",
            "   [REDDIT    ] agentic AI platform site:reddit.com upvotes hot 2025\n",
            "              â†’ 4 new | 210 total\n",
            "   [REDDIT    ] agentic AI platform reddit r/MachineLearning OR r/technology OR r\n",
            "              â†’ 0 new | 210 total\n",
            "   [YOUTUBE   ] agentic AI platform site:youtube.com review demo 2025\n",
            "              â†’ 5 new | 215 total\n",
            "   [YOUTUBE   ] agentic AI platform youtube.com viral video breakdown\n",
            "              â†’ 1 new | 216 total\n",
            "   [BLOGS     ] agentic AI platform site:substack.com 2025\n",
            "              â†’ 5 new | 221 total\n",
            "   [BLOGS     ] agentic AI platform site:medium.com review analysis 2025\n",
            "              â†’ 5 new | 226 total\n",
            "\n",
            "============================================================\n",
            "âœ… SCOUT COMPLETE â€” 226 unique posts\n",
            "   twitter        : 54\n",
            "   youtube        : 42\n",
            "   reddit         : 41\n",
            "   substack       : 30\n",
            "   medium         : 30\n",
            "   linkedin       : 29\n",
            "============================================================\n",
            "\n",
            "\n",
            "ðŸ”¥ VIRAL CONTENT LEADERBOARD â€” Top 20\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#01 ðŸ“¹ [YOUTUBE] ðŸ“„ ARTICLE\n",
            "     ðŸ“° Watch the viral 'ad' that imagines aged Elon Musk, Sam Altman, and Jef\n",
            "     ðŸ”— https://www.businessinsider.com/energym-ad-old-elon-musk-sam-altman-jeff-bezos-aicandy-2026-2\n",
            "     ðŸ·ï¸  OpenAI agents  |  ðŸ“Š 0.0388  |  ðŸ”¥ went viral, repost, views, founder\n",
            "     ðŸ“… Thu, 26 Feb 2026 18:39:18 GMT\n",
            "     ðŸ’¬ It's a doomsday scenario, of course. (It's not clear that any AI job apocalypse is coming soon.) But it's one that resonated: The Instagram Reel has over 4 million views, while acc...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#02 ðŸ“¹ [YOUTUBE] ðŸŽ¬ VIDEO\n",
            "     ðŸ“° ChatGPT Agents: The Complete Guide 2025 (Real Use Cases)\n",
            "     ðŸ”— https://www.youtube.com/watch?v=eICp7o0_xmM\n",
            "     ðŸ·ï¸  OpenAI agents  |  ðŸ“Š 0.9566  |  ðŸ”¥ comments, likes, views, rant\n",
            "     ðŸ’¬ ChatGPT Agents: The Complete Guide 2025 (Real Use Cases)\n",
            "Anik Singal\n",
            "523000 subscribers\n",
            "467 likes\n",
            "17878 views\n",
            "15 Aug 2025\n",
            "ChatGPT Agents: The Complete Guide 2025 | Real Use Cases &...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#03 ðŸ’¼ [LINKEDIN] ðŸ“„ ARTICLE\n",
            "     ðŸ“° Jack Dorseyâ€™s Block to cut nearly half its workforce in AI overhaul, s\n",
            "     ðŸ”— https://www.reuters.com/business/blocks-fourth-quarter-profit-rises-announces-over-4000-job-cuts-2026-02-26/\n",
            "     ðŸ·ï¸  AWS Bedrock  |  ðŸ“Š 0.0088  |  ðŸ”¥ breaking, CEO, exclusive, concern\n",
            "     ðŸ“… Thu, 26 Feb 2026 21:14:29 GMT\n",
            "     ðŸ’¬ , opens new tab\n",
            "\n",
            "### Stay Informed\n",
            "\n",
            "   Download the App (iOS), opens new tab\n",
            "   Download the App (Android), opens new tab\n",
            "   Newsletters\n",
            "   Subscribe\n",
            "\n",
            "### Information you can trust...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#04 ðŸ“¹ [YOUTUBE] ðŸŽ¬ VIDEO\n",
            "     ðŸ“° OpenAI DevDay 2025 - What Hit What Missed - YouTube\n",
            "     ðŸ”— https://www.youtube.com/watch?v=pXGakso13ZM\n",
            "     ðŸ·ï¸  OpenAI agents  |  ðŸ“Š 0.9852  |  ðŸ”¥ comments, likes, views\n",
            "     ðŸ’¬ OpenAI DevDay 2025 - What Hit What Missed\n",
            "Sam Witteveen\n",
            "115000 subscribers\n",
            "307 likes\n",
            "14331 views\n",
            "6 Oct 2025\n",
            "In this video, I go through the key announcements from the OpenAI DevDay...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#05 ðŸ“¹ [YOUTUBE] ðŸŽ¬ VIDEO\n",
            "     ðŸ“° OpenAI DevDay 2025 Updates: ChatGPT Apps, Agent Builder, & More!\n",
            "     ðŸ”— https://www.youtube.com/watch?v=NxKY3rLxfsM\n",
            "     ðŸ·ï¸  OpenAI agents  |  ðŸ“Š 0.983  |  ðŸ”¥ comments, likes, views\n",
            "     ðŸ’¬ OpenAI DevDay 2025 Updates: ChatGPT Apps, Agent Builder, & More!\n",
            "Ryan Doser\n",
            "31700 subscribers\n",
            "18 likes\n",
            "529 views\n",
            "7 Oct 2025\n",
            "OpenAI just dropped major updates at their DevDay 2025 e...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#06 ðŸ’¼ [LINKEDIN] ðŸ“„ ARTICLE\n",
            "     ðŸ“° 5 prompts for Gemini 3.1 that really show off what it can do - TechRad\n",
            "     ðŸ”— https://www.techradar.com/ai-platforms-assistants/gemini/5-prompts-for-gemini-3-1-that-really-show-off-what-it-can-do\n",
            "     ðŸ·ï¸  Google Gemini  |  ðŸ“Š 0.7447  |  ðŸ”¥ breaking, thread, views\n",
            "     ðŸ“… Thu, 26 Feb 2026 19:00:00 GMT\n",
            "     ðŸ’¬ Eric Hal Schwartz\n",
            "\n",
            "Social Links Navigation\n",
            "\n",
            "Contributor\n",
            "\n",
            "Eric Hal Schwartz is a freelance writer for TechRadar with more than 15 years of experience covering the intersection of th...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#07 ðŸ’¼ [LINKEDIN] ðŸ“„ ARTICLE\n",
            "     ðŸ“° Techmagnate, India's Leading SEO Agency, Reinforces AI-First Approach \n",
            "     ðŸ”— https://www.lokmattimes.com/business/techmagnate-indias-leading-seo-agency-reinforces-ai-first-approach-with-structured-workforce-training/\n",
            "     ðŸ·ï¸  agentic AI platform  |  ðŸ“Š 0.5927  |  ðŸ”¥ views, CEO, founder\n",
            "     ðŸ“… Thu, 26 Feb 2026 18:19:44 GMT\n",
            "     ðŸ’¬ Alongside this workforce development, Techmagnate had already introduced an Agentic AI layer within its workflows last year to support content planning, optimisation, and performan...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#08 ðŸ’¼ [LINKEDIN] ðŸ“„ ARTICLE\n",
            "     ðŸ“° Amazon, OpenAI expanding partnership to almost $140B - Chain Store Age\n",
            "     ðŸ”— https://chainstoreage.com/amazon-openai-expanding-partnership-almost-140b\n",
            "     ðŸ·ï¸  AWS Bedrock  |  ðŸ“Š 0.151  |  ðŸ”¥ CEO, exclusive, impressed\n",
            "     ðŸ“… Fri, 27 Feb 2026 10:38:00 GMT\n",
            "     ðŸ’¬ Highlights of the new partnership include:\n",
            "\n",
            " OpenAI and Amazon are jointly developing a Stateful Runtime Environment based on OpenAIâ€™s models, which will be available through the A...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#09 ðŸ“¹ [YOUTUBE] ðŸ“„ ARTICLE\n",
            "     ðŸ“° Google reveals Nano Banana 2 AI image model, coming to Gemini today - \n",
            "     ðŸ”— https://arstechnica.com/ai/2026/02/google-releases-nano-banana-2-ai-image-generator-promises-pro-results-with-flash-speed/\n",
            "     ðŸ·ï¸  Google Gemini  |  ðŸ“Š 0.0988  |  ðŸ”¥ comments, likes, rant\n",
            "     ðŸ“… Thu, 26 Feb 2026 17:12:10 GMT\n",
            "     ðŸ’¬ 59 Comments\n",
            "\n",
            "Comments\n",
            "\n",
            " Forum view\n",
            "\n",
            "Loading comments...\n",
            "\n",
            "Prev story\n",
            "\n",
            "Most Read\n",
            "\n",
            "1. 1. Could a vaccine prevent dementia? Shingles shot data only getting stronger.\n",
            "2. 2. New AirSnitc...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#10 ðŸ“¹ [YOUTUBE] ðŸŽ¬ VIDEO\n",
            "     ðŸ“° 6 Game-Changing Ways to Use Google Gemini AI Tools in 2025\n",
            "     ðŸ”— https://www.youtube.com/watch?v=L6AlsOV5Zyw\n",
            "     ðŸ·ï¸  Google Gemini  |  ðŸ“Š 0.9979  |  ðŸ”¥ thread, views\n",
            "     ðŸ’¬ through complex documents and frame things in simple ways is really, really good now, yeah, and I think it's, it's wild to just\n",
            "reflect on that. This is, like, the V zero of the pr...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#11 ðŸ¤– [REDDIT] ðŸ§µ THREAD\n",
            "     ðŸ“° Agentic AI in 2025, what actually worked this year vs the hype - Reddi\n",
            "     ðŸ”— https://www.reddit.com/r/AI_Agents/comments/1oq43st/agentic_ai_in_2025_what_actually_worked_this_year/\n",
            "     ðŸ·ï¸  agentic AI platform  |  ðŸ“Š 0.9979  |  ðŸ”¥ thread, concern\n",
            "     ðŸ’¬ 2\n",
            "\n",
            "1 more reply\n",
            "\n",
            "1 more reply\n",
            "\n",
            "Continue this thread\n",
            "\n",
            " with idea that 1000s of agents will somehow cooperate to achieve it. It does not exist yet, he wants to build it. I don't beli...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#12 ðŸ“ [SUBSTACK] ðŸ“„ ARTICLE\n",
            "     ðŸ“° Google's AI Check Move: I/O 2025 and the Future of Assistants\n",
            "     ðŸ”— https://substack.com/home/post/p-165032699?utm_campaign=post&utm_medium=web\n",
            "     ðŸ·ï¸  Google Gemini  |  ðŸ“Š 0.9974  |  ðŸ”¥ views, rant\n",
            "     ðŸ’¬ Gemini goes further when acting as your device assistant. If permissions are granted, it can tap into your calendar, contacts, precise location, app usage, and smart home devices. ...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#13 ðŸ¤– [REDDIT] ðŸ§µ THREAD\n",
            "     ðŸ“° In 2025 a popular discussion topic was, \"if AI is so great then where \n",
            "     ðŸ”— https://www.reddit.com/r/ClaudeCode/comments/1qu1j3h/in_2025_a_popular_discussion_topic_was_if_ai_is/\n",
            "     ðŸ·ï¸  Claude AI  |  ðŸ“Š 0.9958  |  ðŸ”¥ comments, upvotes\n",
            "     ðŸ’¬ Image 2: r/ClaudeCode - In 2025 a popular discussion topic was, \"if AI is so great then where are all the new apps?\" Well, here they are.Image 3: r/ClaudeCode - In 2025 a popular d...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#14 ðŸ¤– [REDDIT] ðŸ§µ THREAD\n",
            "     ðŸ“° OpenAI - Reddit\n",
            "     ðŸ”— https://www.reddit.com/r/OpenAI/top/?after=dDNfMXJnYml4cg%3D%3D&sort=top&t=DAY\n",
            "     ðŸ·ï¸  OpenAI agents  |  ðŸ“Š 0.9857  |  ðŸ”¥ thread, comments\n",
            "     ðŸ’¬ Anyone can view, post, and comment to this community. ## r/OpenAI Rules. Keep content posted relevant to OpenAI, or the discussion of Artificial Intelligence. Donâ€™t spam, donâ€™t sta...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#15 ðŸ“¹ [YOUTUBE] ðŸŽ¬ VIDEO\n",
            "     ðŸ“° Introduction to Operator & Agents - YouTube\n",
            "     ðŸ”— https://www.youtube.com/watch?v=CSE77wAdDLg\n",
            "     ðŸ·ï¸  OpenAI agents  |  ðŸ“Š 0.9811  |  ðŸ”¥ comments, views\n",
            "     ðŸ’¬ Introduction to Operator & Agents\n",
            "OpenAI\n",
            "1910000 subscribers\n",
            "\n",
            "863638 views\n",
            "23 Jan 2025\n",
            "Begins at 10am PT\n",
            "\n",
            "Join Sam Altman, Yash Kumar, Casey Chu, and Reiichiro Nakano as they intro...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#16 ðŸ“¹ [YOUTUBE] ðŸŽ¬ VIDEO\n",
            "     ðŸ“° OpenAI DevDay 2025: Opening Keynote with Sam Altman - YouTube\n",
            "     ðŸ”— https://www.youtube.com/watch?v=hS1YqcewH0c\n",
            "     ðŸ·ï¸  OpenAI agents  |  ðŸ“Š 0.9679  |  ðŸ”¥ comments, views\n",
            "     ðŸ’¬ OpenAI DevDay 2025: Opening Keynote with Sam Altman\n",
            "OpenAI\n",
            "1920000 subscribers\n",
            "\n",
            "774390 views\n",
            "6 Oct 2025\n",
            "Sam Altman kicks off DevDay 2025 with a keynote to explore ideas that will c...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#17 ðŸ¤– [REDDIT] ðŸ§µ THREAD\n",
            "     ðŸ“° All the biggest news from AWS' big tech show re:Invent 2025 : r/LLM\n",
            "     ðŸ”— https://www.reddit.com/r/LLM/comments/1pdp3ye/all_the_biggest_news_from_aws_big_tech_show/\n",
            "     ðŸ·ï¸  AWS Bedrock  |  ðŸ“Š 0.9289  |  ðŸ”¥ CEO, concern\n",
            "     ðŸ’¬ | Announcement | Details |\n",
            " --- |\n",
            "|\n",
            "|  |  |\n",
            "| AIâ€‘agent focus | CEO Matt Garman said AI agents can unlock â€œtrue valueâ€ by performing tasks automatically. Viceâ€‘president Swami Sivasu...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#18 ðŸ“¹ [YOUTUBE] ðŸŽ¬ VIDEO\n",
            "     ðŸ“° AI-Powered Threat Detection with AWS Bedrock & Pinecone - Live Demo\n",
            "     ðŸ”— https://www.youtube.com/watch?v=ZTbJbibylAc\n",
            "     ðŸ·ï¸  AWS Bedrock  |  ðŸ“Š 0.8985  |  ðŸ”¥ likes, views\n",
            "     ðŸ’¬ ience with Cyril\n",
            "845 subscribers\n",
            "8 likes\n",
            "96 views\n",
            "28 Aug 2025\n",
            "This is a live demonstration of an automated threat detection system using AWS Bedrock AI, Pinecone vector database, a...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#19 ðŸ“¹ [YOUTUBE] ðŸŽ¬ VIDEO\n",
            "     ðŸ“° How to create AI agents using Gemini on Vertex AI and AI ... - YouTube\n",
            "     ðŸ”— https://www.youtube.com/watch?v=8CaV0AzXvXc\n",
            "     ðŸ·ï¸  GCP Vertex AI  |  ðŸ“Š 0.8293  |  ðŸ”¥ likes, views\n",
            "     ðŸ’¬ # How to create AI agents using Gemini on Vertex AI and AI Studio (demo)\n",
            "## Google Cloud\n",
            "319000 subscribers\n",
            "229 likes\n",
            "\n",
            "### Description\n",
            "12556 views\n",
            "Posted: 3 Apr 2025\n",
            "Learn with Pak...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "#20 ðŸ“¹ [YOUTUBE] ðŸŽ¬ VIDEO\n",
            "     ðŸ“° Claude 4 VS Gemini 2.5 Pro: Who's #1 in 2025? - YouTube\n",
            "     ðŸ”— https://www.youtube.com/watch?v=7Izl2_c7A9o\n",
            "     ðŸ·ï¸  Claude AI  |  ðŸ“Š 0.8015  |  ðŸ”¥ likes, views\n",
            "     ðŸ’¬ is its colossal 1 million token context window. Perfect for analyzing entire documents or vast code bases at once. It also boasts native multimodality, seamlessly handling text, im...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "ðŸ¦ TWITTER â€” 54 results\n",
            "\n",
            "  ðŸ“° AJ's AI (@AJs_AI) / Posts / X\n",
            "  ðŸ”— https://twitter.com/AJs_AI\n",
            "  ðŸ”¥ leaked, exclusive\n",
            "  ðŸ’¬ 6\n",
            "\n",
            "62\n",
            "\n",
            "4.9K\n",
            "\n",
            "Image 23\n",
            "\n",
            "AJâ€™s AI\n",
            "\n",
            "@AJs_AI\n",
            "\n",
            "Â·\n",
            "\n",
            "Mar 9, 2025\n",
            "\n",
            "UPDATED 12pm PST 3/9/25: Iâ€™m officially out of access codes (right now)! It looks like somebody leaked my code so thereâ€™s people who were in th\n",
            "\n",
            "  ðŸ“° Siva Surendira (@theAIsailor) / Posts / X\n",
            "  ðŸ”— https://twitter.com/theAIsailor\n",
            "  ðŸ”¥ thread, founder\n",
            "  ðŸ’¬ A new model. A new framework. A new open-source tool that promises to change everything. The AI community erupts. Twitter threads go viral. Startup founders\n",
            "\n",
            "  ðŸ“° Matt Shumer (@mattshumer_) / Posts / X - Twitter\n",
            "  ðŸ”— https://twitter.com/mattshumer_\n",
            "  ðŸ”¥ repost, founder\n",
            "  ðŸ’¬ Matt Shumer (@mattshumer_) / X\n",
            "\n",
            "Donâ€™t miss whatâ€™s happening\n",
            "\n",
            "People on X are the first to know.\n",
            "\n",
            "Log in\n",
            "\n",
            "Sign up\n",
            "\n",
            " if you're at all curious how things might play out over the next few years.\n",
            "\n",
            "Quote\n",
            "\n",
            "I\n",
            "\n",
            "\n",
            "ðŸ¤– REDDIT â€” 41 results\n",
            "\n",
            "  ðŸ“° Agentic AI in 2025, what actually worked this year vs the hype - Reddit\n",
            "  ðŸ”— https://www.reddit.com/r/AI_Agents/comments/1oq43st/agentic_ai_in_2025_what_actually_worked_this_year/\n",
            "  ðŸ”¥ thread, concern\n",
            "  ðŸ’¬ 2\n",
            "\n",
            "1 more reply\n",
            "\n",
            "1 more reply\n",
            "\n",
            "Continue this thread\n",
            "\n",
            " with idea that 1000s of agents will somehow cooperate to achieve it. It does not exist yet, he wants to build it. I don't believe it is achievable\n",
            "\n",
            "  ðŸ“° In 2025 a popular discussion topic was, \"if AI is so great then where ...\n",
            "  ðŸ”— https://www.reddit.com/r/ClaudeCode/comments/1qu1j3h/in_2025_a_popular_discussion_topic_was_if_ai_is/\n",
            "  ðŸ”¥ comments, upvotes\n",
            "  ðŸ’¬ Image 2: r/ClaudeCode - In 2025 a popular discussion topic was, \"if AI is so great then where are all the new apps?\" Well, here they are.Image 3: r/ClaudeCode - In 2025 a popular discussion topic was,\n",
            "\n",
            "  ðŸ“° OpenAI - Reddit\n",
            "  ðŸ”— https://www.reddit.com/r/OpenAI/top/?after=dDNfMXJnYml4cg%3D%3D&sort=top&t=DAY\n",
            "  ðŸ”¥ thread, comments\n",
            "  ðŸ’¬ Anyone can view, post, and comment to this community. ## r/OpenAI Rules. Keep content posted relevant to OpenAI, or the discussion of Artificial Intelligence. Donâ€™t spam, donâ€™t start arguments, toxici\n",
            "\n",
            "\n",
            "ðŸ“¹ YOUTUBE â€” 42 results\n",
            "\n",
            "  ðŸ“° Watch the viral 'ad' that imagines aged Elon Musk, Sam Altman, and Jeff Bezos promoting a creepy energy source for AI - Business Insider\n",
            "  ðŸ”— https://www.businessinsider.com/energym-ad-old-elon-musk-sam-altman-jeff-bezos-aicandy-2026-2\n",
            "  ðŸ”¥ went viral, repost, views, founder, exclusive\n",
            "  ðŸ’¬ It's a doomsday scenario, of course. (It's not clear that any AI job apocalypse is coming soon.) But it's one that resonated: The Instagram Reel has over 4 million views, while accounts continue to re\n",
            "\n",
            "  ðŸ“° ChatGPT Agents: The Complete Guide 2025 (Real Use Cases)\n",
            "  ðŸ”— https://www.youtube.com/watch?v=eICp7o0_xmM\n",
            "  ðŸ”¥ comments, likes, views, rant\n",
            "  ðŸ’¬ ChatGPT Agents: The Complete Guide 2025 (Real Use Cases)\n",
            "Anik Singal\n",
            "523000 subscribers\n",
            "467 likes\n",
            "17878 views\n",
            "15 Aug 2025\n",
            "ChatGPT Agents: The Complete Guide 2025 | Real Use Cases & Business Workflows\n",
            "\n",
            "\n",
            "  ðŸ“° OpenAI DevDay 2025 - What Hit What Missed - YouTube\n",
            "  ðŸ”— https://www.youtube.com/watch?v=pXGakso13ZM\n",
            "  ðŸ”¥ comments, likes, views\n",
            "  ðŸ’¬ OpenAI DevDay 2025 - What Hit What Missed\n",
            "Sam Witteveen\n",
            "115000 subscribers\n",
            "307 likes\n",
            "14331 views\n",
            "6 Oct 2025\n",
            "In this video, I go through the key announcements from the OpenAI DevDay keynote. \n",
            "\n",
            "Blog for\n",
            "\n",
            "âœ… Saved: tavily_scout_output.json + tavily_scout_urls.json\n",
            "Twitter Bearer Token: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "ðŸ¦ Twitter: 'OpenAI agents'\n",
            "   â¤ï¸     1  ðŸ”    0  ðŸ’¬    1 | @adaptAIbility_: Perplexity just quietly killed the â€˜chatbot eraâ€™. ðŸš¨\n",
            "\n",
            "Weâ€™re entering the age of a\n",
            "   â¤ï¸     0  ðŸ”    0  ðŸ’¬    1 | @TechBriefAI: OpenAI and AWS Launch Stateful Runtime Environment for Agents in Bedrock\n",
            "   â¤ï¸     0  ðŸ”    0  ðŸ’¬    1 | @ai_news_flash_: Sources:\n",
            "https://t.co/5nWodVrTL0\n",
            "https://t.co/tz0i7p7D15\n",
            "https://t.co/DYrhsNuvGT\n",
            "ðŸ¦ Twitter: 'Claude AI'\n",
            "   â¤ï¸     0  ðŸ”    0  ðŸ’¬    0 | @Appman1981: @Geiger_Capital Claude is superior and Trump has no clue of AI.\n",
            "   â¤ï¸     0  ðŸ”    0  ðŸ’¬    0 | @LokiTheCrazyCat: @ACMilanSanDiego @PeteHegseth @Doug__J @AnthropicAI @DarioAmodei @POTUS @claudea\n",
            "   â¤ï¸     0  ðŸ”    0  ðŸ’¬    0 | @PIRATE_ANZU: @lyc_aon @Anarseldain it's not about their safety \"rails\", it's about the whole \n",
            "ðŸ¦ Twitter: 'Google Gemini'\n",
            "   â¤ï¸     1  ðŸ”    0  ðŸ’¬    1 | @fortziyon: @avavidan @grok The big 3 are Anthropic (Claude), OpenAI (GPT) and Google (Gemin\n",
            "   â¤ï¸     0  ðŸ”    0  ðŸ’¬    1 | @NoSingingTV: @DaveShapi @grok, how do you handle things like this? Do you try to make changes\n",
            "   â¤ï¸     1  ðŸ”    0  ðŸ’¬    0 | @primordialseed: so to get this straight... when i buy google stock, i get exposure into:\n",
            "\n",
            "- gemi\n",
            "ðŸ¦ Twitter: 'AWS Bedrock'\n",
            "   â¤ï¸    16  ðŸ”    0  ðŸ’¬    1 | @awscloud: @OpenAI Together, we're co-creating a Stateful Runtime Environment powered by Op\n",
            "   â¤ï¸     0  ðŸ”    0  ðŸ’¬    1 | @TechBriefAI: OpenAI and AWS Launch Stateful Runtime Environment for Agents in Bedrock\n",
            "   â¤ï¸     0  ðŸ”    0  ðŸ’¬    1 | @ai_news_flash_: Sources:\n",
            "https://t.co/5nWodVrTL0\n",
            "https://t.co/tz0i7p7D15\n",
            "https://t.co/DYrhsNuvGT\n",
            "ðŸ¦ Twitter: 'GCP Vertex AI'\n",
            "   â¤ï¸    16  ðŸ”    0  ðŸ’¬    4 | @ZackKorman: @HackingLZ I actually donâ€™t really agree with this take (sort of). Even with fro\n",
            "   â¤ï¸     2  ðŸ”    2  ðŸ’¬    0 | @akaclandestine: GitHub - JoshuaProvoste/CVE-2026-2472-Vertex-AI-SDK-Google-Cloud: Technical PoC \n",
            "   â¤ï¸     1  ðŸ”    0  ðŸ’¬    1 | @VanillaCache: @alexcloudstar Absolutely, feel the time ticking as is ðŸ˜…\n",
            "\n",
            "Still on vercel though\n",
            "ðŸ¦ Twitter: 'agentic AI platform'\n",
            "   â¤ï¸     7  ðŸ”    0  ðŸ’¬    4 | @Sam_Badawi: Jamin Ball at @AltimeterCap argues that $XYZ Block's 40% RIF is not merely cost \n",
            "   â¤ï¸     1  ðŸ”    0  ðŸ’¬    1 | @SD8nger: @grok @EdwinLennox80 @Allibendo @PeteHegseth @AnthropicAI @DarioAmodei @POTUS Me\n",
            "   â¤ï¸     1  ðŸ”    0  ðŸ’¬    1 | @REDBIKEJohn: Everyone talks about missing Bitcoin in 2010.\n",
            "\n",
            "You are missing something bigger \n",
            "âœ… Saved 59 tweets â†’ yutori_twitter_output.json\n"
          ]
        }
      ],
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# TAVILY SOCIAL SCOUT + YUTORI TWITTER DEEP SCOUT\n",
        "# Multi-Agent Viral Content Pipeline â€” Step 1b\n",
        "#\n",
        "# Run in Google Colab:\n",
        "!pip install tavily-python requests -q\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from getpass import getpass\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from typing import List, Optional, Dict\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "\n",
        "# â”€â”€ Install â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "!pip install tavily-python requests -q\n",
        "\n",
        "from tavily import TavilyClient\n",
        "import requests\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# CONFIG â€” edit these\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "TOPICS = [\n",
        "    \"OpenAI agents\",\n",
        "    \"Claude AI\",\n",
        "    \"Google Gemini\",\n",
        "    \"AWS Bedrock\",\n",
        "    \"GCP Vertex AI\",\n",
        "    \"agentic AI platform\",\n",
        "]\n",
        "\n",
        "PLATFORMS = {\n",
        "    \"twitter\":   True,\n",
        "    \"linkedin\":  True,\n",
        "    \"reddit\":    True,\n",
        "    \"youtube\":   True,\n",
        "    \"blogs\":     True,\n",
        "    \"instagram\": False,   # limited text content via Tavily\n",
        "}\n",
        "\n",
        "RECENCY      = \"week\"   # \"day\" | \"week\" | \"month\"\n",
        "MAX_RESULTS  = 5       # results per query\n",
        "USE_YUTORI   = True   # flip True + add Twitter Bearer Token for deep Twitter scrape\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# DATA STRUCTURES\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "@dataclass\n",
        "class ScoutedPost:\n",
        "    platform:        str\n",
        "    content_type:    str\n",
        "    title:           str\n",
        "    url:             str\n",
        "    snippet:         str\n",
        "    full_content:    str\n",
        "    relevance_score: float\n",
        "    topic:           str\n",
        "    query_used:      str\n",
        "    published_date:  Optional[str]       = None\n",
        "    viral_signals:   List[str]           = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class ScoutOutput:\n",
        "    agent:             str       = \"tavily_social_scout\"\n",
        "    timestamp:         str       = field(default_factory=lambda: datetime.utcnow().isoformat())\n",
        "    topics_scouted:    List[str] = field(default_factory=list)\n",
        "    platforms_scouted: List[str] = field(default_factory=list)\n",
        "    posts:             List[ScoutedPost] = field(default_factory=list)\n",
        "    total_found:       int       = 0\n",
        "    queries_run:       int       = 0\n",
        "    status:            str       = \"success\"\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# QUERY TEMPLATES â€” engineered to surface viral / high-engagement content\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "QUERY_TEMPLATES = {\n",
        "\n",
        "    \"twitter\": [\n",
        "        \"{topic} site:twitter.com viral thread 2025\",\n",
        "        \"{topic} site:x.com trending\",\n",
        "        \"{topic} CEO founder tweet thread site:twitter.com\",\n",
        "    ],\n",
        "\n",
        "    \"linkedin\": [\n",
        "        \"{topic} site:linkedin.com CEO founder post viral\",\n",
        "        \"{topic} linkedin.com/posts reactions comments\",\n",
        "        \"{topic} site:linkedin.com 2025 trending\",\n",
        "    ],\n",
        "\n",
        "    \"reddit\": [\n",
        "        \"{topic} site:reddit.com upvotes hot 2025\",\n",
        "        \"{topic} reddit r/MachineLearning OR r/technology OR r/LocalLLaMA\",\n",
        "        \"{topic} reddit r/artificial OR r/singularity discussion\",\n",
        "    ],\n",
        "\n",
        "    \"youtube\": [\n",
        "        \"{topic} site:youtube.com review demo 2025\",\n",
        "        \"{topic} youtube.com viral video breakdown\",\n",
        "        \"{topic} CEO interview keynote youtube 2025\",\n",
        "    ],\n",
        "\n",
        "    \"blogs\": [\n",
        "        \"{topic} site:substack.com 2025\",\n",
        "        \"{topic} site:medium.com review analysis 2025\",\n",
        "        \"{topic} developer review opinion breakdown 2025\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "VIRAL_SIGNAL_WORDS = [\n",
        "    \"went viral\", \"blew up\", \"breaking\", \"just announced\",\n",
        "    \"everyone is talking\", \"hot take\", \"thread\", \"repost\",\n",
        "    \"comments\", \"likes\", \"upvotes\", \"views\",\n",
        "    \"CEO\", \"founder\", \"leaked\", \"exclusive\", \"first look\",\n",
        "    \"rant\", \"grief\", \"concern\", \"disappointed\", \"impressed\",\n",
        "]\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# HELPERS\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def detect_viral_signals(text: str) -> List[str]:\n",
        "    text_lower = text.lower()\n",
        "    return [s for s in VIRAL_SIGNAL_WORDS if s.lower() in text_lower]\n",
        "\n",
        "def detect_platform(url: str, intended: str) -> str:\n",
        "    u = url.lower()\n",
        "    if \"twitter.com\" in u or \"x.com\" in u: return \"twitter\"\n",
        "    if \"linkedin.com\"  in u:               return \"linkedin\"\n",
        "    if \"reddit.com\"    in u:               return \"reddit\"\n",
        "    if \"youtube.com\"   in u or \"youtu.be\" in u: return \"youtube\"\n",
        "    if \"substack.com\"  in u:               return \"substack\"\n",
        "    if \"medium.com\"    in u:               return \"medium\"\n",
        "    if \"instagram.com\" in u:               return \"instagram\"\n",
        "    return intended\n",
        "\n",
        "def detect_content_type(url: str, title: str) -> str:\n",
        "    u, t = url.lower(), title.lower()\n",
        "    if \"twitter.com\" in u or \"x.com\" in u:\n",
        "        return \"thread\" if \"thread\" in t else \"post\"\n",
        "    if \"youtube.com\" in u or \"youtu.be\" in u: return \"video\"\n",
        "    if \"reddit.com\"  in u:                    return \"thread\"\n",
        "    if \"linkedin.com\" in u:                   return \"post\"\n",
        "    if any(w in t for w in [\"review\",\"analysis\",\"breakdown\",\"rant\"]): return \"review\"\n",
        "    return \"article\"\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# TAVILY SOCIAL SCOUT\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "class TavilySocialScout:\n",
        "\n",
        "    def __init__(self, api_key: str):\n",
        "        self.client = TavilyClient(api_key=api_key)\n",
        "\n",
        "    def _run_query(self, query: str, topic: str, platform: str,\n",
        "                   recency: str, max_results: int) -> List[ScoutedPost]:\n",
        "        days_map = {\"day\": 2, \"week\": 7, \"month\": 30}\n",
        "        try:\n",
        "            resp = self.client.search(\n",
        "                query=query,\n",
        "                search_depth=\"advanced\",\n",
        "                max_results=max_results,\n",
        "                topic=\"news\",\n",
        "                days=days_map.get(recency, 2),\n",
        "                include_answer=False,\n",
        "                include_raw_content=False,\n",
        "            )\n",
        "        except Exception:\n",
        "            try:\n",
        "                resp = self.client.search(\n",
        "                    query=query,\n",
        "                    search_depth=\"advanced\",\n",
        "                    max_results=max_results,\n",
        "                    include_answer=False,\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"      âš ï¸  Query failed: {e}\")\n",
        "                return []\n",
        "\n",
        "        posts = []\n",
        "        for r in resp.get(\"results\", []):\n",
        "            url     = r.get(\"url\", \"\")\n",
        "            title   = r.get(\"title\", \"\")\n",
        "            content = r.get(\"content\", \"\")\n",
        "            posts.append(ScoutedPost(\n",
        "                platform        = detect_platform(url, platform),\n",
        "                content_type    = detect_content_type(url, title),\n",
        "                title           = title,\n",
        "                url             = url,\n",
        "                snippet         = content[:400],\n",
        "                full_content    = content,\n",
        "                relevance_score = round(r.get(\"score\", 0.0), 4),\n",
        "                topic           = topic,\n",
        "                query_used      = query,\n",
        "                published_date  = r.get(\"published_date\"),\n",
        "                viral_signals   = detect_viral_signals(content),\n",
        "            ))\n",
        "        return posts\n",
        "\n",
        "    def run(self, topics, platforms, recency=\"day\", max_results=5) -> ScoutOutput:\n",
        "        active = [p for p, on in platforms.items() if on]\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ðŸ“¡ TAVILY SOCIAL SCOUT\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"   Topics    : {topics}\")\n",
        "        print(f\"   Platforms : {active}\")\n",
        "        print(f\"   Recency   : last {recency}\")\n",
        "\n",
        "        output   = ScoutOutput(topics_scouted=topics, platforms_scouted=active)\n",
        "        seen     = set()\n",
        "        q_count  = 0\n",
        "\n",
        "        for topic in topics:\n",
        "            print(f\"\\nðŸ”Ž Topic: '{topic}'\")\n",
        "            for platform, enabled in platforms.items():\n",
        "                if not enabled:\n",
        "                    continue\n",
        "                for template in QUERY_TEMPLATES.get(platform, [])[:2]:\n",
        "                    query = template.replace(\"{topic}\", topic)\n",
        "                    print(f\"   [{platform.upper():10s}] {query[:65]}\")\n",
        "                    posts = self._run_query(query, topic, platform, recency, max_results)\n",
        "                    q_count += 1\n",
        "                    new = 0\n",
        "                    for p in posts:\n",
        "                        if p.url not in seen:\n",
        "                            seen.add(p.url)\n",
        "                            output.posts.append(p)\n",
        "                            new += 1\n",
        "                    print(f\"              â†’ {new} new | {len(output.posts)} total\")\n",
        "                    time.sleep(0.3)\n",
        "\n",
        "        # Rank: viral signal count first, then relevance score\n",
        "        output.posts.sort(key=lambda p: (len(p.viral_signals), p.relevance_score), reverse=True)\n",
        "        output.total_found = len(output.posts)\n",
        "        output.queries_run = q_count\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"âœ… SCOUT COMPLETE â€” {output.total_found} unique posts\")\n",
        "        plat_counts = Counter(p.platform for p in output.posts)\n",
        "        for plat, cnt in plat_counts.most_common():\n",
        "            print(f\"   {plat:15s}: {cnt}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "        return output\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# YUTORI / TWITTER v2 DEEP SCOUT (optional)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def search_twitter_recent(query: str, bearer_token: str, max_results: int = 20) -> list:\n",
        "    \"\"\"\n",
        "    Hits Twitter v2 recent search API.\n",
        "    Returns tweets sorted by engagement (likes + retweetsÃ—3 + repliesÃ—2).\n",
        "    \"\"\"\n",
        "    url     = \"https://api.twitter.com/2/tweets/search/recent\"\n",
        "    headers = {\"Authorization\": f\"Bearer {bearer_token}\"}\n",
        "    params  = {\n",
        "        \"query\":        f\"{query} -is:retweet lang:en\",\n",
        "        \"max_results\":  min(max_results, 100),\n",
        "        \"tweet.fields\": \"public_metrics,created_at,author_id,entities\",\n",
        "        \"expansions\":   \"author_id\",\n",
        "        \"user.fields\":  \"name,username,verified,public_metrics\",\n",
        "    }\n",
        "\n",
        "    resp = requests.get(url, headers=headers, params=params)\n",
        "    resp.raise_for_status()\n",
        "    data  = resp.json()\n",
        "    tweets = data.get(\"data\", [])\n",
        "    users  = {u[\"id\"]: u for u in data.get(\"includes\", {}).get(\"users\", [])}\n",
        "\n",
        "    results = []\n",
        "    for t in tweets:\n",
        "        m      = t.get(\"public_metrics\", {})\n",
        "        author = users.get(t.get(\"author_id\", \"\"), {})\n",
        "        results.append({\n",
        "            \"tweet_id\":         t[\"id\"],\n",
        "            \"url\":              f\"https://twitter.com/{author.get('username','')}/status/{t['id']}\",\n",
        "            \"text\":             t[\"text\"],\n",
        "            \"author\":           author.get(\"name\", \"\"),\n",
        "            \"username\":         author.get(\"username\", \"\"),\n",
        "            \"verified\":         author.get(\"verified\", False),\n",
        "            \"author_followers\": author.get(\"public_metrics\", {}).get(\"followers_count\", 0),\n",
        "            \"likes\":            m.get(\"like_count\", 0),\n",
        "            \"retweets\":         m.get(\"retweet_count\", 0),\n",
        "            \"replies\":          m.get(\"reply_count\", 0),\n",
        "            \"engagement\":       m.get(\"like_count\", 0) + m.get(\"retweet_count\", 0) * 3 + m.get(\"reply_count\", 0) * 2,\n",
        "            \"created_at\":       t.get(\"created_at\", \"\"),\n",
        "        })\n",
        "\n",
        "    results.sort(key=lambda x: x[\"engagement\"], reverse=True)\n",
        "    return results\n",
        "\n",
        "\n",
        "def run_yutori_scout(topics: List[str], bearer_token: str, max_results: int = 10) -> list:\n",
        "    all_tweets = []\n",
        "    for topic in topics:\n",
        "        print(f\"ðŸ¦ Twitter: '{topic}'\")\n",
        "        tweets = search_twitter_recent(topic, bearer_token, max_results)\n",
        "        all_tweets.extend(tweets)\n",
        "        for t in tweets[:3]:\n",
        "            print(f\"   â¤ï¸ {t['likes']:5d}  ðŸ” {t['retweets']:4d}  ðŸ’¬ {t['replies']:4d} | @{t['username']}: {t['text'][:80]}\")\n",
        "    all_tweets.sort(key=lambda x: x[\"engagement\"], reverse=True)\n",
        "    return all_tweets\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# DISPLAY HELPERS\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "PLATFORM_EMOJI = {\n",
        "    \"twitter\": \"ðŸ¦\", \"linkedin\": \"ðŸ’¼\", \"reddit\": \"ðŸ¤–\",\n",
        "    \"youtube\": \"ðŸ“¹\", \"substack\": \"ðŸ“\", \"medium\": \"ðŸ“°\",\n",
        "    \"blog\": \"ðŸŒ\",   \"instagram\": \"ðŸ“¸\",\n",
        "}\n",
        "TYPE_EMOJI = {\n",
        "    \"thread\": \"ðŸ§µ\", \"post\": \"ðŸ“Œ\", \"video\": \"ðŸŽ¬\",\n",
        "    \"article\": \"ðŸ“„\", \"review\": \"â­\",\n",
        "}\n",
        "\n",
        "def print_leaderboard(output: ScoutOutput, limit: int = 20):\n",
        "    print(f\"\\nðŸ”¥ VIRAL CONTENT LEADERBOARD â€” Top {min(limit, output.total_found)}\\n\")\n",
        "    print(\"â”€\" * 70)\n",
        "    for i, p in enumerate(output.posts[:limit]):\n",
        "        pe      = PLATFORM_EMOJI.get(p.platform, \"ðŸŒ\")\n",
        "        te      = TYPE_EMOJI.get(p.content_type, \"ðŸ“„\")\n",
        "        signals = \", \".join(p.viral_signals[:4]) or \"none\"\n",
        "        print(f\"#{i+1:02d} {pe} [{p.platform.upper()}] {te} {p.content_type.upper()}\")\n",
        "        print(f\"     ðŸ“° {p.title[:70]}\")\n",
        "        print(f\"     ðŸ”— {p.url}\")\n",
        "        print(f\"     ðŸ·ï¸  {p.topic}  |  ðŸ“Š {p.relevance_score}  |  ðŸ”¥ {signals}\")\n",
        "        if p.published_date:\n",
        "            print(f\"     ðŸ“… {p.published_date}\")\n",
        "        print(f\"     ðŸ’¬ {p.snippet[:180]}...\")\n",
        "        print(\"â”€\" * 70)\n",
        "\n",
        "def show_platform(output: ScoutOutput, platform_name: str, limit: int = 5):\n",
        "    filtered = [p for p in output.posts if p.platform == platform_name]\n",
        "    print(f\"\\n{PLATFORM_EMOJI.get(platform_name,'ðŸŒ')} {platform_name.upper()} â€” {len(filtered)} results\\n\")\n",
        "    for p in filtered[:limit]:\n",
        "        print(f\"  ðŸ“° {p.title}\")\n",
        "        print(f\"  ðŸ”— {p.url}\")\n",
        "        print(f\"  ðŸ”¥ {', '.join(p.viral_signals[:5]) or 'no signals'}\")\n",
        "        print(f\"  ðŸ’¬ {p.snippet[:200]}\\n\")\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# MAIN\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # â”€â”€ API keys â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    TAVILY_API_KEY = getpass(\"Tavily API key: \")\n",
        "\n",
        "    # â”€â”€ Run Tavily social scout â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    scout        = TavilySocialScout(api_key=TAVILY_API_KEY)\n",
        "    scout_output = scout.run(\n",
        "        topics      = TOPICS,\n",
        "        platforms   = PLATFORMS,\n",
        "        recency     = RECENCY,\n",
        "        max_results = MAX_RESULTS,\n",
        "    )\n",
        "\n",
        "    # â”€â”€ Print leaderboard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    print_leaderboard(scout_output, limit=20)\n",
        "\n",
        "    # â”€â”€ Per-platform views â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    for plat in [\"twitter\", \"reddit\", \"youtube\"]:\n",
        "        show_platform(scout_output, plat, limit=3)\n",
        "\n",
        "    # â”€â”€ Save outputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    with open(\"tavily_scout_output.json\", \"w\") as f:\n",
        "        json.dump(asdict(scout_output), f, indent=2, default=str)\n",
        "\n",
        "    url_list = [\n",
        "        {\n",
        "            \"rank\":          i + 1,\n",
        "            \"platform\":      p[\"platform\"],\n",
        "            \"content_type\":  p[\"content_type\"],\n",
        "            \"title\":         p[\"title\"],\n",
        "            \"url\":           p[\"url\"],\n",
        "            \"score\":         p[\"relevance_score\"],\n",
        "            \"viral_signals\": p[\"viral_signals\"],\n",
        "            \"topic\":         p[\"topic\"],\n",
        "            \"published_date\":p[\"published_date\"],\n",
        "        }\n",
        "        for i, p in enumerate(asdict(scout_output)[\"posts\"])\n",
        "    ]\n",
        "    with open(\"tavily_scout_urls.json\", \"w\") as f:\n",
        "        json.dump(url_list, f, indent=2)\n",
        "\n",
        "    print(\"âœ… Saved: tavily_scout_output.json + tavily_scout_urls.json\")\n",
        "\n",
        "    # â”€â”€ Optional Yutori / Twitter v2 deep scout â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    if USE_YUTORI:\n",
        "        TWITTER_BEARER = getpass(\"Twitter Bearer Token: \")\n",
        "        twitter_results = run_yutori_scout(TOPICS, TWITTER_BEARER, max_results=10)\n",
        "        with open(\"yutori_twitter_output.json\", \"w\") as f:\n",
        "            json.dump(twitter_results, f, indent=2)\n",
        "        print(f\"âœ… Saved {len(twitter_results)} tweets â†’ yutori_twitter_output.json\")\n",
        "    else:\n",
        "        print(\"â„¹ï¸  Yutori disabled. Set USE_YUTORI = True to enable.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# TAVILY SCOUT FILTER + SCORER\n",
        "# Multi-Agent Viral Content Pipeline â€” Step 1c\n",
        "#\n",
        "# Reads:  tavily_scout_output.json  (223 posts from Step 1b)\n",
        "# Writes: scout_filtered.json       (top N posts â€” Reka-ready)\n",
        "#         scout_filtered_urls.json  (clean URL list)\n",
        "#\n",
        "# Scoring logic:\n",
        "#   - Engagement signals (likes, views, comments, retweets in snippet)\n",
        "#   - Recency boost (last 24h > last 48h > older)\n",
        "#   - Platform weight (twitter/reddit > youtube > linkedin > blog)\n",
        "#   - Content type weight (thread/video/rant > article)\n",
        "#   - Controversy signals (grief, rant, concern, disappointed)\n",
        "#   - Hype signals (insane, viral, breaking, exclusive, first look)\n",
        "#   - Author authority (CEO, founder, verified)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from typing import List, Optional, Tuple\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# CONFIG\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "INPUT_FILE          = \"tavily_scout_output.json\"\n",
        "OUTPUT_FILE         = \"scout_filtered.json\"\n",
        "OUTPUT_URLS_FILE    = \"scout_filtered_urls.json\"\n",
        "\n",
        "TOP_N               = 25     # how many posts to pass to Reka\n",
        "MIN_SCORE           = 0.10   # drop anything below this threshold\n",
        "\n",
        "# How many posts per platform max (prevents one platform flooding Reka)\n",
        "MAX_PER_PLATFORM    = 8\n",
        "\n",
        "# Which content types to prioritize for VIDEO generation\n",
        "PREFERRED_TYPES     = [\"video\", \"thread\", \"review\", \"post\", \"article\"]\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# SCORING WEIGHTS\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "PLATFORM_WEIGHT = {\n",
        "    \"twitter\":   1.4,\n",
        "    \"reddit\":    1.3,\n",
        "    \"youtube\":   1.2,\n",
        "    \"substack\":  1.0,\n",
        "    \"medium\":    0.9,\n",
        "    \"linkedin\":  0.8,\n",
        "    \"instagram\": 0.6,\n",
        "}\n",
        "\n",
        "CONTENT_TYPE_WEIGHT = {\n",
        "    \"video\":    1.3,\n",
        "    \"thread\":   1.2,\n",
        "    \"review\":   1.1,\n",
        "    \"post\":     1.0,\n",
        "    \"article\":  0.9,\n",
        "}\n",
        "\n",
        "# Signals and their score contribution\n",
        "HYPE_SIGNALS = {\n",
        "    \"went viral\":    0.20,\n",
        "    \"breaking\":      0.15,\n",
        "    \"exclusive\":     0.12,\n",
        "    \"first look\":    0.12,\n",
        "    \"just announced\":0.10,\n",
        "    \"insane\":        0.10,\n",
        "    \"impressed\":     0.08,\n",
        "}\n",
        "\n",
        "CONTROVERSY_SIGNALS = {\n",
        "    \"grief\":         0.18,\n",
        "    \"rant\":          0.16,\n",
        "    \"concern\":       0.12,\n",
        "    \"disappointed\":  0.12,\n",
        "    \"hot take\":      0.10,\n",
        "    \"everyone is talking\": 0.10,\n",
        "}\n",
        "\n",
        "AUTHORITY_SIGNALS = {\n",
        "    \"CEO\":           0.15,\n",
        "    \"founder\":       0.12,\n",
        "    \"verified\":      0.10,\n",
        "    \"leaked\":        0.14,\n",
        "    \"president\":     0.10,\n",
        "}\n",
        "\n",
        "# Regex patterns to extract raw engagement numbers from snippet text\n",
        "ENGAGEMENT_PATTERNS = {\n",
        "    \"views\":    [\n",
        "        r\"([\\d,\\.]+[KkMm]?)\\s*views\",\n",
        "        r\"([\\d,\\.]+[KkMm]?)\\s*view\",\n",
        "    ],\n",
        "    \"likes\":    [\n",
        "        r\"([\\d,\\.]+[KkMm]?)\\s*likes\",\n",
        "        r\"([\\d,\\.]+[KkMm]?)\\s*like\",\n",
        "    ],\n",
        "    \"comments\": [\n",
        "        r\"([\\d,\\.]+[KkMm]?)\\s*[Cc]omments\",\n",
        "        r\"([\\d,\\.]+[KkMm]?)\\s*replies\",\n",
        "    ],\n",
        "    \"subs\": [\n",
        "        r\"([\\d,\\.]+[KkMm]?)\\s*subscribers\",\n",
        "    ],\n",
        "    \"reposts\": [\n",
        "        r\"([\\d,\\.]+[KkMm]?)\\s*reposts?\",\n",
        "        r\"([\\d,\\.]+[KkMm]?)\\s*retweets?\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# HELPERS\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def parse_num(s: str) -> float:\n",
        "    \"\"\"Convert '4.9K', '1.6M', '139K' â†’ float.\"\"\"\n",
        "    s = s.replace(\",\", \"\").strip()\n",
        "    multipliers = {\"k\": 1_000, \"m\": 1_000_000, \"b\": 1_000_000_000}\n",
        "    if s and s[-1].lower() in multipliers:\n",
        "        return float(s[:-1]) * multipliers[s[-1].lower()]\n",
        "    try:\n",
        "        return float(s)\n",
        "    except ValueError:\n",
        "        return 0.0\n",
        "\n",
        "def extract_engagement(text: str) -> dict:\n",
        "    \"\"\"Pull raw numbers from snippet text. Returns dict of metric â†’ value.\"\"\"\n",
        "    metrics = {}\n",
        "    for metric, patterns in ENGAGEMENT_PATTERNS.items():\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                metrics[metric] = parse_num(match.group(1))\n",
        "                break\n",
        "    return metrics\n",
        "\n",
        "def engagement_score(metrics: dict) -> float:\n",
        "    \"\"\"Normalize engagement numbers into a 0â€“1 score.\"\"\"\n",
        "    views    = metrics.get(\"views\", 0)\n",
        "    likes    = metrics.get(\"likes\", 0)\n",
        "    comments = metrics.get(\"comments\", 0)\n",
        "    reposts  = metrics.get(\"reposts\", 0)\n",
        "    subs     = metrics.get(\"subs\", 0)\n",
        "\n",
        "    # Raw engagement score (weighted sum)\n",
        "    raw = (\n",
        "        views    * 1.0 +\n",
        "        likes    * 3.0 +\n",
        "        comments * 4.0 +\n",
        "        reposts  * 5.0 +\n",
        "        subs     * 0.1\n",
        "    )\n",
        "    # Normalize: cap at 10M, log scale\n",
        "    import math\n",
        "    if raw <= 0:\n",
        "        return 0.0\n",
        "    return min(math.log10(raw + 1) / 7.0, 1.0)   # log10(10M) â‰ˆ 7\n",
        "\n",
        "def recency_score(published_date: Optional[str]) -> float:\n",
        "    \"\"\"Return 1.0 if today, 0.7 if yesterday, 0.4 if older, 0.2 if unknown.\"\"\"\n",
        "    if not published_date:\n",
        "        return 0.2\n",
        "    try:\n",
        "        # Handle RFC 2822 and ISO formats\n",
        "        for fmt in [\n",
        "            \"%a, %d %b %Y %H:%M:%S %Z\",\n",
        "            \"%a, %d %b %Y %H:%M:%S %z\",\n",
        "            \"%Y-%m-%dT%H:%M:%S\",\n",
        "            \"%Y-%m-%dT%H:%M:%SZ\",\n",
        "            \"%Y-%m-%d\",\n",
        "        ]:\n",
        "            try:\n",
        "                dt = datetime.strptime(published_date.strip(), fmt)\n",
        "                if dt.tzinfo is None:\n",
        "                    dt = dt.replace(tzinfo=timezone.utc)\n",
        "                break\n",
        "            except ValueError:\n",
        "                continue\n",
        "        else:\n",
        "            return 0.2\n",
        "\n",
        "        now   = datetime.now(timezone.utc)\n",
        "        delta = now - dt\n",
        "\n",
        "        if delta < timedelta(hours=24):  return 1.0\n",
        "        if delta < timedelta(hours=48):  return 0.7\n",
        "        if delta < timedelta(days=7):    return 0.4\n",
        "        return 0.2\n",
        "\n",
        "    except Exception:\n",
        "        return 0.2\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# SCORER\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "@dataclass\n",
        "class ScoredPost:\n",
        "    # Original fields\n",
        "    platform:        str\n",
        "    content_type:    str\n",
        "    title:           str\n",
        "    url:             str\n",
        "    snippet:         str\n",
        "    full_content:    str\n",
        "    relevance_score: float\n",
        "    topic:           str\n",
        "    published_date:  Optional[str]\n",
        "    viral_signals:   List[str]\n",
        "\n",
        "    # Computed scores\n",
        "    final_score:        float = 0.0\n",
        "    engagement_score:   float = 0.0\n",
        "    recency_score:      float = 0.0\n",
        "    signal_score:       float = 0.0\n",
        "    authority_score:    float = 0.0\n",
        "    platform_weight:    float = 1.0\n",
        "    content_type_weight:float = 1.0\n",
        "    engagement_metrics: dict  = field(default_factory=dict)\n",
        "    score_breakdown:    dict  = field(default_factory=dict)\n",
        "\n",
        "\n",
        "def score_post(raw: dict) -> ScoredPost:\n",
        "    text = (raw.get(\"title\", \"\") + \" \" + raw.get(\"snippet\", \"\") + \" \" + raw.get(\"full_content\", \"\"))\n",
        "\n",
        "    # Extract engagement numbers\n",
        "    eng_metrics = extract_engagement(text)\n",
        "    eng_s       = engagement_score(eng_metrics)\n",
        "\n",
        "    # Recency\n",
        "    rec_s = recency_score(raw.get(\"published_date\"))\n",
        "\n",
        "    # Hype signals\n",
        "    hype_s = sum(\n",
        "        weight for signal, weight in HYPE_SIGNALS.items()\n",
        "        if signal.lower() in text.lower()\n",
        "    )\n",
        "\n",
        "    # Controversy signals\n",
        "    cont_s = sum(\n",
        "        weight for signal, weight in CONTROVERSY_SIGNALS.items()\n",
        "        if signal.lower() in text.lower()\n",
        "    )\n",
        "\n",
        "    # Authority signals\n",
        "    auth_s = sum(\n",
        "        weight for signal, weight in AUTHORITY_SIGNALS.items()\n",
        "        if signal.lower() in text.lower()\n",
        "    )\n",
        "\n",
        "    signal_s    = min(hype_s + cont_s, 1.0)\n",
        "    platform_w  = PLATFORM_WEIGHT.get(raw.get(\"platform\", \"\"), 1.0)\n",
        "    type_w      = CONTENT_TYPE_WEIGHT.get(raw.get(\"content_type\", \"\"), 1.0)\n",
        "    tavily_s    = raw.get(\"relevance_score\", 0.0)\n",
        "\n",
        "    # Final weighted score\n",
        "    final = (\n",
        "        eng_s       * 0.30 +\n",
        "        rec_s       * 0.20 +\n",
        "        signal_s    * 0.20 +\n",
        "        tavily_s    * 0.15 +\n",
        "        auth_s      * 0.15\n",
        "    ) * platform_w * type_w\n",
        "\n",
        "    return ScoredPost(\n",
        "        platform         = raw.get(\"platform\", \"\"),\n",
        "        content_type     = raw.get(\"content_type\", \"\"),\n",
        "        title            = raw.get(\"title\", \"\"),\n",
        "        url              = raw.get(\"url\", \"\"),\n",
        "        snippet          = raw.get(\"snippet\", \"\"),\n",
        "        full_content     = raw.get(\"full_content\", \"\"),\n",
        "        relevance_score  = raw.get(\"relevance_score\", 0.0),\n",
        "        topic            = raw.get(\"topic\", \"\"),\n",
        "        published_date   = raw.get(\"published_date\"),\n",
        "        viral_signals    = raw.get(\"viral_signals\", []),\n",
        "        final_score      = round(final, 4),\n",
        "        engagement_score = round(eng_s, 4),\n",
        "        recency_score    = round(rec_s, 4),\n",
        "        signal_score     = round(signal_s, 4),\n",
        "        authority_score  = round(auth_s, 4),\n",
        "        platform_weight  = platform_w,\n",
        "        content_type_weight = type_w,\n",
        "        engagement_metrics  = eng_metrics,\n",
        "        score_breakdown  = {\n",
        "            \"engagement\":   round(eng_s * 0.30, 4),\n",
        "            \"recency\":      round(rec_s * 0.20, 4),\n",
        "            \"signals\":      round(signal_s * 0.20, 4),\n",
        "            \"tavily\":       round(tavily_s * 0.15, 4),\n",
        "            \"authority\":    round(auth_s * 0.15, 4),\n",
        "            \"platform_mul\": platform_w,\n",
        "            \"type_mul\":     type_w,\n",
        "        },\n",
        "    )\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# FILTER + RANK\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "def filter_and_rank(\n",
        "    posts: list,\n",
        "    top_n: int             = TOP_N,\n",
        "    min_score: float       = MIN_SCORE,\n",
        "    max_per_platform: int  = MAX_PER_PLATFORM,\n",
        ") -> Tuple[List[ScoredPost], dict]:\n",
        "\n",
        "    # Score all\n",
        "    scored = [score_post(p) for p in posts]\n",
        "\n",
        "    # Drop below threshold\n",
        "    scored = [p for p in scored if p.final_score >= min_score]\n",
        "\n",
        "    # Sort by final score\n",
        "    scored.sort(key=lambda p: p.final_score, reverse=True)\n",
        "\n",
        "    # Per-platform cap to ensure diversity\n",
        "    platform_counts = defaultdict(int)\n",
        "    diverse = []\n",
        "    for p in scored:\n",
        "        if platform_counts[p.platform] < max_per_platform:\n",
        "            diverse.append(p)\n",
        "            platform_counts[p.platform] += 1\n",
        "\n",
        "    top = diverse[:top_n]\n",
        "\n",
        "    stats = {\n",
        "        \"total_input\":    len(posts),\n",
        "        \"after_threshold\":len(scored),\n",
        "        \"after_diversity\": len(diverse),\n",
        "        \"final_selected\": len(top),\n",
        "        \"platform_distribution\": dict(platform_counts),\n",
        "        \"score_range\": {\n",
        "            \"max\": round(top[0].final_score, 4) if top else 0,\n",
        "            \"min\": round(top[-1].final_score, 4) if top else 0,\n",
        "        },\n",
        "    }\n",
        "    return top, stats\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# DISPLAY\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "PLATFORM_EMOJI = {\n",
        "    \"twitter\": \"ðŸ¦\", \"linkedin\": \"ðŸ’¼\", \"reddit\": \"ðŸ¤–\",\n",
        "    \"youtube\": \"ðŸ“¹\", \"substack\": \"ðŸ“\", \"medium\": \"ðŸ“°\",\n",
        "    \"blog\": \"ðŸŒ\",   \"instagram\": \"ðŸ“¸\",\n",
        "}\n",
        "TYPE_EMOJI = {\n",
        "    \"thread\": \"ðŸ§µ\", \"post\": \"ðŸ“Œ\", \"video\": \"ðŸŽ¬\",\n",
        "    \"article\": \"ðŸ“„\", \"review\": \"â­\",\n",
        "}\n",
        "\n",
        "def print_filtered(posts: List[ScoredPost], stats: dict):\n",
        "    print(f\"\\n{'='*65}\")\n",
        "    print(f\"ðŸŽ¯ FILTERED LEADERBOARD â€” Top {stats['final_selected']} posts for Reka\")\n",
        "    print(f\"{'='*65}\")\n",
        "    print(f\"   Input   : {stats['total_input']} posts\")\n",
        "    print(f\"   Dropped : {stats['total_input'] - stats['after_threshold']} below threshold\")\n",
        "    print(f\"   Selected: {stats['final_selected']}\")\n",
        "    print(f\"   Score range: {stats['score_range']['min']} â€“ {stats['score_range']['max']}\")\n",
        "    print(f\"\\n   Platform mix:\")\n",
        "    for plat, cnt in sorted(stats['platform_distribution'].items(), key=lambda x: -x[1]):\n",
        "        print(f\"     {PLATFORM_EMOJI.get(plat,'ðŸŒ')} {plat:12s}: {cnt}\")\n",
        "    print()\n",
        "\n",
        "    for i, p in enumerate(posts):\n",
        "        pe = PLATFORM_EMOJI.get(p.platform, \"ðŸŒ\")\n",
        "        te = TYPE_EMOJI.get(p.content_type, \"ðŸ“„\")\n",
        "\n",
        "        # Build engagement string\n",
        "        eng_parts = []\n",
        "        m = p.engagement_metrics\n",
        "        if m.get(\"views\"):    eng_parts.append(f\"ðŸ‘ {int(m['views']):,}\")\n",
        "        if m.get(\"likes\"):    eng_parts.append(f\"â¤ï¸ {int(m['likes']):,}\")\n",
        "        if m.get(\"comments\"): eng_parts.append(f\"ðŸ’¬ {int(m['comments']):,}\")\n",
        "        if m.get(\"reposts\"):  eng_parts.append(f\"ðŸ” {int(m['reposts']):,}\")\n",
        "        if m.get(\"subs\"):     eng_parts.append(f\"ðŸ‘¤ {int(m['subs']):,} subs\")\n",
        "        eng_str = \"  \".join(eng_parts) if eng_parts else \"no metrics extracted\"\n",
        "\n",
        "        print(f\"#{i+1:02d} {'â–ˆ' * int(p.final_score * 20):<20} {p.final_score:.3f}\")\n",
        "        print(f\"    {pe} {p.platform.upper():10s}  {te} {p.content_type.upper()}\")\n",
        "        print(f\"    ðŸ“° {p.title[:72]}\")\n",
        "        print(f\"    ðŸ”— {p.url}\")\n",
        "        print(f\"    ðŸ·ï¸  {p.topic}\")\n",
        "        if eng_str != \"no metrics extracted\":\n",
        "            print(f\"    ðŸ“Š {eng_str}\")\n",
        "        if p.published_date:\n",
        "            print(f\"    ðŸ“… {p.published_date[:30]}\")\n",
        "        print(f\"    ðŸ”¥ signals: {', '.join(p.viral_signals[:4]) or 'none'}\")\n",
        "        print(f\"    ðŸ“ˆ breakdown â†’ eng:{p.score_breakdown['engagement']:.3f} \"\n",
        "              f\"rec:{p.score_breakdown['recency']:.3f} \"\n",
        "              f\"sig:{p.score_breakdown['signals']:.3f} \"\n",
        "              f\"auth:{p.score_breakdown['authority']:.3f}\")\n",
        "        print(f\"    ðŸ’¬ {p.snippet[:160]}...\")\n",
        "        print()\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# MAIN\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # â”€â”€ Load scout output â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    print(f\"ðŸ“‚ Loading {INPUT_FILE}...\")\n",
        "    with open(INPUT_FILE, \"r\") as f:\n",
        "        raw_data = json.load(f)\n",
        "\n",
        "    posts = raw_data.get(\"posts\", [])\n",
        "    print(f\"   {len(posts)} posts loaded\")\n",
        "    print(f\"   Topics: {raw_data.get('topics_scouted', [])}\")\n",
        "    print(f\"   Scouted: {raw_data.get('timestamp', '')[:19]}\")\n",
        "\n",
        "    # â”€â”€ Score + filter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    print(f\"\\nâš™ï¸  Scoring all {len(posts)} posts...\")\n",
        "    top_posts, stats = filter_and_rank(\n",
        "        posts,\n",
        "        top_n            = TOP_N,\n",
        "        min_score        = MIN_SCORE,\n",
        "        max_per_platform = MAX_PER_PLATFORM,\n",
        "    )\n",
        "\n",
        "    # â”€â”€ Display â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    print_filtered(top_posts, stats)\n",
        "\n",
        "    # â”€â”€ Save full filtered output (for Reka) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    output = {\n",
        "        \"agent\":            \"scout_filter\",\n",
        "        \"timestamp\":        datetime.now(timezone.utc).isoformat(),\n",
        "        \"source_file\":      INPUT_FILE,\n",
        "        \"filter_config\": {\n",
        "            \"top_n\":            TOP_N,\n",
        "            \"min_score\":        MIN_SCORE,\n",
        "            \"max_per_platform\": MAX_PER_PLATFORM,\n",
        "        },\n",
        "        \"stats\":    stats,\n",
        "        \"posts\":    [asdict(p) for p in top_posts],\n",
        "    }\n",
        "\n",
        "    with open(OUTPUT_FILE, \"w\") as f:\n",
        "        json.dump(output, f, indent=2, default=str)\n",
        "\n",
        "    # â”€â”€ Save clean URL list â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    url_list = [\n",
        "        {\n",
        "            \"rank\":             i + 1,\n",
        "            \"final_score\":      p.final_score,\n",
        "            \"platform\":         p.platform,\n",
        "            \"content_type\":     p.content_type,\n",
        "            \"title\":            p.title,\n",
        "            \"url\":              p.url,\n",
        "            \"topic\":            p.topic,\n",
        "            \"published_date\":   p.published_date,\n",
        "            \"viral_signals\":    p.viral_signals,\n",
        "            \"engagement\":       p.engagement_metrics,\n",
        "            \"score_breakdown\":  p.score_breakdown,\n",
        "            \"snippet\":          p.snippet[:300],\n",
        "        }\n",
        "        for i, p in enumerate(top_posts)\n",
        "    ]\n",
        "\n",
        "    with open(OUTPUT_URLS_FILE, \"w\") as f:\n",
        "        json.dump(url_list, f, indent=2, default=str)\n",
        "\n",
        "    print(f\"\\nâœ… Saved:\")\n",
        "    print(f\"   {OUTPUT_FILE}       â†’ Reka Agent (Step 2) full input\")\n",
        "    print(f\"   {OUTPUT_URLS_FILE}  â†’ ranked URL list\")\n",
        "    print(f\"\\n   Feed '{OUTPUT_FILE}' into Reka Agent as tavily_data.\")\n",
        "    print(f\"\\n{'='*65}\")\n",
        "    print(f\"Pipeline:\")\n",
        "    print(f\"  âœ… Tavily Scout (223 posts)\")\n",
        "    print(f\"  âœ… Scout Filter ({len(top_posts)} posts â†’ Reka-ready)\")\n",
        "    print(f\"  ðŸ§  Reka Agent  â† next\")\n",
        "    print(f\"{'='*65}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH8stzcf7uRo",
        "outputId": "40afa353-10b1-4d4b-d526-b9efe4313cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“‚ Loading tavily_scout_output.json...\n",
            "   226 posts loaded\n",
            "   Topics: ['OpenAI agents', 'Claude AI', 'Google Gemini', 'AWS Bedrock', 'GCP Vertex AI', 'agentic AI platform']\n",
            "   Scouted: 2026-02-27T22:13:07\n",
            "\n",
            "âš™ï¸  Scoring all 226 posts...\n",
            "\n",
            "=================================================================\n",
            "ðŸŽ¯ FILTERED LEADERBOARD â€” Top 25 posts for Reka\n",
            "=================================================================\n",
            "   Input   : 226 posts\n",
            "   Dropped : 20 below threshold\n",
            "   Selected: 25\n",
            "   Score range: 0.2341 â€“ 0.6949\n",
            "\n",
            "   Platform mix:\n",
            "     ðŸ“¹ youtube     : 8\n",
            "     ðŸ¦ twitter     : 8\n",
            "     ðŸ¤– reddit      : 8\n",
            "     ðŸ’¼ linkedin    : 8\n",
            "     ðŸ“ substack    : 8\n",
            "     ðŸ“° medium      : 8\n",
            "\n",
            "#01 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        0.695\n",
            "    ðŸ“¹ YOUTUBE     ðŸŽ¬ VIDEO\n",
            "    ðŸ“° Introduction to Operator & Agents - YouTube\n",
            "    ðŸ”— https://www.youtube.com/watch?v=CSE77wAdDLg\n",
            "    ðŸ·ï¸  OpenAI agents\n",
            "    ðŸ“Š ðŸ‘ 863,638  ðŸ’¬ 1,809  ðŸ‘¤ 1,910,000 subs\n",
            "    ðŸ”¥ signals: comments, views\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.258 rec:0.040 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ Introduction to Operator & Agents\n",
            "OpenAI\n",
            "1910000 subscribers\n",
            "\n",
            "863638 views\n",
            "23 Jan 2025\n",
            "Begins at 10am PT\n",
            "\n",
            "Join Sam Altman, Yash Kumar, Casey Chu, and Reiichiro ...\n",
            "\n",
            "#02 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        0.689\n",
            "    ðŸ“¹ YOUTUBE     ðŸŽ¬ VIDEO\n",
            "    ðŸ“° OpenAI DevDay 2025: Opening Keynote with Sam Altman - YouTube\n",
            "    ðŸ”— https://www.youtube.com/watch?v=hS1YqcewH0c\n",
            "    ðŸ·ï¸  OpenAI agents\n",
            "    ðŸ“Š ðŸ‘ 774,390  ðŸ’¬ 952  ðŸ‘¤ 1,920,000 subs\n",
            "    ðŸ”¥ signals: comments, views\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.257 rec:0.040 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ OpenAI DevDay 2025: Opening Keynote with Sam Altman\n",
            "OpenAI\n",
            "1920000 subscribers\n",
            "\n",
            "774390 views\n",
            "6 Oct 2025\n",
            "Sam Altman kicks off DevDay 2025 with a keynote to explo...\n",
            "\n",
            "#03 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        0.661\n",
            "    ðŸ“¹ YOUTUBE     ðŸŽ¬ VIDEO\n",
            "    ðŸ“° ChatGPT Agents: The Complete Guide 2025 (Real Use Cases)\n",
            "    ðŸ”— https://www.youtube.com/watch?v=eICp7o0_xmM\n",
            "    ðŸ·ï¸  OpenAI agents\n",
            "    ðŸ“Š ðŸ‘ 17,878  â¤ï¸ 467  ðŸ’¬ 30  ðŸ‘¤ 523,000 subs\n",
            "    ðŸ”¥ signals: comments, likes, views, rant\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.208 rec:0.040 sig:0.032 auth:0.000\n",
            "    ðŸ’¬ ChatGPT Agents: The Complete Guide 2025 (Real Use Cases)\n",
            "Anik Singal\n",
            "523000 subscribers\n",
            "467 likes\n",
            "17878 views\n",
            "15 Aug 2025\n",
            "ChatGPT Agents: The Complete Guide 202...\n",
            "\n",
            "#04 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          0.589\n",
            "    ðŸ“¹ YOUTUBE     ðŸŽ¬ VIDEO\n",
            "    ðŸ“° OpenAI DevDay 2025 - What Hit What Missed - YouTube\n",
            "    ðŸ”— https://www.youtube.com/watch?v=pXGakso13ZM\n",
            "    ðŸ·ï¸  OpenAI agents\n",
            "    ðŸ“Š ðŸ‘ 14,331  â¤ï¸ 307  ðŸ’¬ 28  ðŸ‘¤ 115,000 subs\n",
            "    ðŸ”¥ signals: comments, likes, views\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.190 rec:0.040 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ OpenAI DevDay 2025 - What Hit What Missed\n",
            "Sam Witteveen\n",
            "115000 subscribers\n",
            "307 likes\n",
            "14331 views\n",
            "6 Oct 2025\n",
            "In this video, I go through the key announcements fr...\n",
            "\n",
            "#05 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          0.568\n",
            "    ðŸ¦ TWITTER     ðŸ“Œ POST\n",
            "    ðŸ“° a unified platform that lets AI agents navigate business software ... - \n",
            "    ðŸ”— https://x.com/michaeljburry/status/2027242703847669831\n",
            "    ðŸ·ï¸  OpenAI agents\n",
            "    ðŸ“Š ðŸ‘ 134,000\n",
            "    ðŸ”¥ signals: views\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.220 rec:0.040 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ Cassandra Unchained on X: \"This sounds more than familiar. OpenAI describes Frontier as a â€œsemantic layer for the enterpriseâ€â€”a unified platform that lets AI ag...\n",
            "\n",
            "#06 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          0.568\n",
            "    ðŸ“¹ YOUTUBE     ðŸŽ¬ VIDEO\n",
            "    ðŸ“° How to create AI agents using Gemini on Vertex AI and AI ... - YouTube\n",
            "    ðŸ”— https://www.youtube.com/watch?v=8CaV0AzXvXc\n",
            "    ðŸ·ï¸  GCP Vertex AI\n",
            "    ðŸ“Š ðŸ‘ 12,556  â¤ï¸ 229  ðŸ‘¤ 319,000 subs\n",
            "    ðŸ”¥ signals: likes, views\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.200 rec:0.040 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ # How to create AI agents using Gemini on Vertex AI and AI Studio (demo)\n",
            "## Google Cloud\n",
            "319000 subscribers\n",
            "229 likes\n",
            "\n",
            "### Description\n",
            "12556 views\n",
            "Posted: 3 Apr...\n",
            "\n",
            "#07 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          0.564\n",
            "    ðŸ“¹ YOUTUBE     ðŸŽ¬ VIDEO\n",
            "    ðŸ“° Vertex AI Agent Builder Tutorial & Review (For Beginners) - YouTube\n",
            "    ðŸ”— https://www.youtube.com/watch?v=sTrtE3S4pDI\n",
            "    ðŸ·ï¸  GCP Vertex AI\n",
            "    ðŸ“Š ðŸ‘ 17,694  â¤ï¸ 197  ðŸ‘¤ 354,000 subs\n",
            "    ðŸ”¥ signals: likes, views\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.203 rec:0.040 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ # Vertex AI Agent Builder Tutorial & Review (For Beginners)\n",
            "## How to Digital\n",
            "354000 subscribers\n",
            "197 likes\n",
            "\n",
            "### Description\n",
            "17694 views\n",
            "Posted: 1 Aug 2025\n",
            "Learn...\n",
            "\n",
            "#08 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           0.532\n",
            "    ðŸ“¹ YOUTUBE     ðŸŽ¬ VIDEO\n",
            "    ðŸ“° OpenAI DevDay 2025 Updates: ChatGPT Apps, Agent Builder, & More!\n",
            "    ðŸ”— https://www.youtube.com/watch?v=NxKY3rLxfsM\n",
            "    ðŸ·ï¸  OpenAI agents\n",
            "    ðŸ“Š ðŸ‘ 529  â¤ï¸ 18  ðŸ’¬ 13  ðŸ‘¤ 31,700 subs\n",
            "    ðŸ”¥ signals: comments, likes, views\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.153 rec:0.040 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ OpenAI DevDay 2025 Updates: ChatGPT Apps, Agent Builder, & More!\n",
            "Ryan Doser\n",
            "31700 subscribers\n",
            "18 likes\n",
            "529 views\n",
            "7 Oct 2025\n",
            "OpenAI just dropped major updates at...\n",
            "\n",
            "#09 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           0.511\n",
            "    ðŸ¤– REDDIT      â­ REVIEW\n",
            "    ðŸ“° Redditâ€™s Transformation From Snarky Reviews to Beauty Marketing Tool - W\n",
            "    ðŸ”— https://wwd.com/beauty-industry-news/beauty-features/reddit-transformation-fsnarky-reviews-beauty-marketing-tool-1238553633/\n",
            "    ðŸ·ï¸  Google Gemini\n",
            "    ðŸ“… Fri, 27 Feb 2026 05:01:00 GMT\n",
            "    ðŸ”¥ signals: founder\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.000 rec:0.200 sig:0.000 auth:0.018\n",
            "    ðŸ’¬ Jacob St. John, founder and chief executive officer of Navigo Marketing, said: â€œWe have a lot of brands that are more quiet observers on Reddit, and others that...\n",
            "\n",
            "#10 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           0.504\n",
            "    ðŸ“¹ YOUTUBE     ðŸŽ¬ VIDEO\n",
            "    ðŸ“° AWS re:Invent 2025 - Improve agent quality in production ... - YouTube\n",
            "    ðŸ”— https://www.youtube.com/watch?v=Gcje6pRGr1g\n",
            "    ðŸ·ï¸  AWS Bedrock\n",
            "    ðŸ“Š ðŸ‘ 3,571  â¤ï¸ 51  ðŸ‘¤ 172,000 subs\n",
            "    ðŸ”¥ signals: likes, views\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.185 rec:0.040 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ ### Description\n",
            "3571 views\n",
            "Posted: 5 Dec 2025\n",
            "Amazon Bedrock AgentCore Evaluations provides developers with a unified way to test and validate AI agent performa...\n",
            "\n",
            "#11 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             0.448\n",
            "    ðŸ¤– REDDIT      ðŸ§µ THREAD\n",
            "    ðŸ“° In 2025 a popular discussion topic was, \"if AI is so great then where ..\n",
            "    ðŸ”— https://www.reddit.com/r/ClaudeCode/comments/1qu1j3h/in_2025_a_popular_discussion_topic_was_if_ai_is/\n",
            "    ðŸ·ï¸  Claude AI\n",
            "    ðŸ“Š ðŸ’¬ 47\n",
            "    ðŸ”¥ signals: comments, upvotes\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.098 rec:0.040 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ Image 2: r/ClaudeCode - In 2025 a popular discussion topic was, \"if AI is so great then where are all the new apps?\" Well, here they are.Image 3: r/ClaudeCode -...\n",
            "\n",
            "#12 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              0.376\n",
            "    ðŸ¤– REDDIT      ðŸ§µ THREAD\n",
            "    ðŸ“° All the biggest news from AWS' big tech show re:Invent 2025 : r/LLM\n",
            "    ðŸ”— https://www.reddit.com/r/LLM/comments/1pdp3ye/all_the_biggest_news_from_aws_big_tech_show/\n",
            "    ðŸ·ï¸  AWS Bedrock\n",
            "    ðŸ”¥ signals: CEO, concern\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.000 rec:0.040 sig:0.024 auth:0.037\n",
            "    ðŸ’¬ | Announcement | Details |\n",
            " --- |\n",
            "|\n",
            "|  |  |\n",
            "| AIâ€‘agent focus | CEO Matt Garman said AI agents can unlock â€œtrue valueâ€ by performing tasks automatically. Viceâ€‘pr...\n",
            "\n",
            "#13 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              0.373\n",
            "    ðŸ¦ TWITTER     ðŸ“Œ POST\n",
            "    ðŸ“° Vertex AI update on February 17, 2026 https://t.co/YshefuFukA ...\n",
            "    ðŸ”— https://x.com/gcpweekly/status/2024568430704107659\n",
            "    ðŸ·ï¸  GCP Vertex AI\n",
            "    ðŸ“Š ðŸ‘ 60\n",
            "    ðŸ”¥ signals: views\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.076 rec:0.040 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ GCP Weekly (@gcpweekly). 60 views. Vertex AI update on February 17, 2026 https://t.co/YshefuFukA #googlecloud Deprecated Vertex AI Feature...\n",
            "\n",
            "#14 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              0.368\n",
            "    ðŸ¤– REDDIT      ðŸ“„ ARTICLE\n",
            "    ðŸ“° Sam Altman Insists He Also Has Principles as Anthropicâ€™s Pentagon Stand \n",
            "    ðŸ”— https://gizmodo.com/sam-altman-insists-he-also-has-principles-as-anthropics-pentagon-stand-off-continues-2000727678\n",
            "    ðŸ·ï¸  Claude AI\n",
            "    ðŸ“… Fri, 27 Feb 2026 19:45:09 GMT\n",
            "    ðŸ”¥ signals: none\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.000 rec:0.200 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ The Pentagon gave Anthropic, the makers of Claude, an ultimatum: allow the military unfettered access to its AI model, even if the potential uses violate the co...\n",
            "\n",
            "#15 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               0.346\n",
            "    ðŸ¤– REDDIT      ðŸ§µ THREAD\n",
            "    ðŸ“° Best AI Tools 2025: Hands-On Reviews & Winners by Use-Case\n",
            "    ðŸ”— https://www.reddit.com/r/AiReviewInsiderHQ/comments/1oatp8k/best_ai_tools_2025_handson_reviews_winners_by/\n",
            "    ðŸ·ï¸  agentic AI platform\n",
            "    ðŸ”¥ signals: rant\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.000 rec:0.040 sig:0.032 auth:0.000\n",
            "    ðŸ’¬ LangChain Agents: The de facto framework for developers creating multi-tool reasoning pipelines. It integrates APIs, databases, and actions with human approval ...\n",
            "\n",
            "#16 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               0.333\n",
            "    ðŸ¤– REDDIT      ðŸ§µ THREAD\n",
            "    ðŸ“° Agentic AI in 2025, what actually worked this year vs the hype - Reddit\n",
            "    ðŸ”— https://www.reddit.com/r/AI_Agents/comments/1oq43st/agentic_ai_in_2025_what_actually_worked_this_year/\n",
            "    ðŸ·ï¸  agentic AI platform\n",
            "    ðŸ”¥ signals: thread, concern\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.000 rec:0.040 sig:0.024 auth:0.000\n",
            "    ðŸ’¬ 2\n",
            "\n",
            "1 more reply\n",
            "\n",
            "1 more reply\n",
            "\n",
            "Continue this thread\n",
            "\n",
            " with idea that 1000s of agents will somehow cooperate to achieve it. It does not exist yet, he wants to bu...\n",
            "\n",
            "#17 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               0.327\n",
            "    ðŸ¤– REDDIT      ðŸ§µ THREAD\n",
            "    ðŸ“° How did you like AWS re:Invent 2025? : r/Cloudvisor - Reddit\n",
            "    ðŸ”— https://www.reddit.com/r/Cloudvisor/comments/1pgcsbr/how_did_you_like_aws_reinvent_2025/\n",
            "    ðŸ·ï¸  AWS Bedrock\n",
            "    ðŸ”¥ signals: disappointed\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.000 rec:0.040 sig:0.024 auth:0.000\n",
            "    ðŸ’¬ r/Cloudvisor icon\n",
            "\n",
            "# How did you like AWS re:Invent 2025?\n",
            "\n",
            "Soâ€¦ re:Invent 2025 is officially over.\n",
            "\n",
            "What did you think this year?\n",
            "\n",
            "Any standout launches, session...\n",
            "\n",
            "#18 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                0.298\n",
            "    ðŸ¦ TWITTER     ðŸ“Œ POST\n",
            "    ðŸ“° AJ's AI (@AJs_AI) / Posts / X\n",
            "    ðŸ”— https://twitter.com/AJs_AI\n",
            "    ðŸ·ï¸  OpenAI agents\n",
            "    ðŸ“Š ðŸ” 1\n",
            "    ðŸ”¥ signals: leaked, exclusive\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.033 rec:0.040 sig:0.024 auth:0.021\n",
            "    ðŸ’¬ 6\n",
            "\n",
            "62\n",
            "\n",
            "4.9K\n",
            "\n",
            "Image 23\n",
            "\n",
            "AJâ€™s AI\n",
            "\n",
            "@AJs_AI\n",
            "\n",
            "Â·\n",
            "\n",
            "Mar 9, 2025\n",
            "\n",
            "UPDATED 12pm PST 3/9/25: Iâ€™m officially out of access codes (right now)! It looks like somebody leaked ...\n",
            "\n",
            "#19 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                0.296\n",
            "    ðŸ¤– REDDIT      ðŸ§µ THREAD\n",
            "    ðŸ“° Agentic AI in 2025: Reality Vs the Hype : r/ChatGPT - Reddit\n",
            "    ðŸ”— https://www.reddit.com/r/ChatGPT/comments/1pvd8bi/agentic_ai_in_2025_reality_vs_the_hype/\n",
            "    ðŸ·ï¸  agentic AI platform\n",
            "    ðŸ”¥ signals: none\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.000 rec:0.040 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ r/ChatGPT icon\n",
            "\n",
            "# Agentic AI in 2025: Reality Vs the Hype\n",
            "\n",
            "Spent the whole year building AI agents for everything from support routing to data cleanup, and hone...\n",
            "\n",
            "#20 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                0.276\n",
            "    ðŸ¦ TWITTER     ðŸ“Œ POST\n",
            "    ðŸ“° Anthropic's Claude Code Security Tool Rattles Cybersecuri... - X\n",
            "    ðŸ”— https://x.com/i/trending/2024911717789007997\n",
            "    ðŸ·ï¸  Claude AI\n",
            "    ðŸ”¥ signals: none\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.000 rec:0.040 sig:0.000 auth:0.015\n",
            "    ðŸ’¬ Anthropic's Claude Code Security Tool Triggers Cybersecurity Stock Plunge / X\n",
            "\n",
            "Donâ€™t miss whatâ€™s happening\n",
            "\n",
            "People on X are the first to know.\n",
            "\n",
            "Log in\n",
            "\n",
            "Sign up\n",
            "...\n",
            "\n",
            "#21 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                0.275\n",
            "    ðŸ¦ TWITTER     ðŸ“Œ POST\n",
            "    ðŸ“° Amazon (@amazon) on X\n",
            "    ðŸ”— https://x.com/amazon/status/2027445227922067868\n",
            "    ðŸ·ï¸  AWS Bedrock\n",
            "    ðŸ”¥ signals: exclusive\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.000 rec:0.040 sig:0.024 auth:0.000\n",
            "    ðŸ’¬ Amazon on X: \"OpenAI and Amazon announce strategic partnership\" / X\n",
            "\n",
            "Donâ€™t miss whatâ€™s happening\n",
            "\n",
            "People on X are the first to know.\n",
            "\n",
            "Log in\n",
            "\n",
            "Sign up\n",
            "\n",
            " and Open...\n",
            "\n",
            "#22 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                0.266\n",
            "    ðŸ¦ TWITTER     ðŸ“Œ POST\n",
            "    ðŸ“° Tech Fusionist - Demystifying the Claude AI Buzz - X\n",
            "    ðŸ”— https://x.com/techyoutbe/status/2026542874305966236\n",
            "    ðŸ·ï¸  Claude AI\n",
            "    ðŸ”¥ signals: none\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.000 rec:0.040 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ The reason Claude is trending isn't just about cool new features. It's because we are watching the moment AI stops being just a fun chatbot and...\n",
            "\n",
            "#23 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                0.266\n",
            "    ðŸ¦ TWITTER     ðŸ“Œ POST\n",
            "    ðŸ“° The rise of agentic AI is changing the economics of the IT services ...\n",
            "    ðŸ”— https://x.com/ETtech/status/2021420052965359944\n",
            "    ðŸ·ï¸  agentic AI platform\n",
            "    ðŸ”¥ signals: none\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.000 rec:0.040 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ Experts told ET that the launch of tools such as Claude Cowork and OpenAI's Agent platform will further push this trend....\n",
            "\n",
            "#24 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                0.266\n",
            "    ðŸ¦ TWITTER     ðŸ“Œ POST\n",
            "    ðŸ“° AI research is accelerating. On January 2nd I claimed that Claude ...\n",
            "    ðŸ”— https://x.com/ahall_research/status/2025282331997798585\n",
            "    ðŸ·ï¸  Claude AI\n",
            "    ðŸ”¥ signals: none\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.000 rec:0.040 sig:0.000 auth:0.000\n",
            "    ðŸ’¬ Progress in adopting Claude Code and other AI tools and using them to produce research is going faster than I expected, and it seems plausible...\n",
            "\n",
            "#25 â–ˆâ–ˆâ–ˆâ–ˆ                 0.234\n",
            "    ðŸ’¼ LINKEDIN    ðŸ“„ ARTICLE\n",
            "    ðŸ“° 5 prompts for Gemini 3.1 that really show off what it can do - TechRadar\n",
            "    ðŸ”— https://www.techradar.com/ai-platforms-assistants/gemini/5-prompts-for-gemini-3-1-that-really-show-off-what-it-can-do\n",
            "    ðŸ·ï¸  Google Gemini\n",
            "    ðŸ“Š â¤ï¸ 3\n",
            "    ðŸ“… Thu, 26 Feb 2026 19:00:00 GMT\n",
            "    ðŸ”¥ signals: breaking, thread, views\n",
            "    ðŸ“ˆ breakdown â†’ eng:0.043 rec:0.140 sig:0.030 auth:0.000\n",
            "    ðŸ’¬ Eric Hal Schwartz\n",
            "\n",
            "Social Links Navigation\n",
            "\n",
            "Contributor\n",
            "\n",
            "Eric Hal Schwartz is a freelance writer for TechRadar with more than 15 years of experience covering th...\n",
            "\n",
            "\n",
            "âœ… Saved:\n",
            "   scout_filtered.json       â†’ Reka Agent (Step 2) full input\n",
            "   scout_filtered_urls.json  â†’ ranked URL list\n",
            "\n",
            "   Feed 'scout_filtered.json' into Reka Agent as tavily_data.\n",
            "\n",
            "=================================================================\n",
            "Pipeline:\n",
            "  âœ… Tavily Scout (223 posts)\n",
            "  âœ… Scout Filter (25 posts â†’ Reka-ready)\n",
            "  ðŸ§  Reka Agent  â† next\n",
            "=================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fWgWBA3j_MT4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}